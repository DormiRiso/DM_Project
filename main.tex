\documentclass[10pt,twocolumn]{article}


\usepackage[utf8]{inputenc}
\usepackage{abstract}
\usepackage{geometry}
\usepackage{blindtext}
\usepackage{titlesec}
\usepackage{graphicx}
\usepackage[italian]{babel}
\usepackage[colorlinks=true, linkcolor=black]{hyperref}
\usepackage{amsmath}

\graphicspath{ {./figures/} }

\geometry{a4paper, top=2.5cm, bottom=2.5cm, left=2cm, right=2cm}
\setlength{\absleftindent}{3cm}
\setlength{\absrightindent}{3cm}

\title{Data Mining: Fundamentals prima consegna}
\author{Leonardo Amabile, Michelangelo Leoni, Jacopo Omodei}
\date{\today}


\begin{document}

\twocolumn[
\maketitle % need full-width title
\begin{onecolabstract}


In questo progetto abbiamo pulito, analizzato e trasformato il \textit{dataset} di BoardGameGeek, correggendo valori errati, riducendo la dimensionalità tramite tecniche di aggregazione e creando un insieme di dati più coerente e interpretabile. Abbiamo studiato distribuzioni, correlazioni e categorie, e applicato varie tecniche di \textit{clustering}, che non hanno evidenziato gruppi distinti ma suggeriscono uno spettro continuo di caratteristiche nei giochi da tavolo. Il \textit{dataset} finale risulta adatto ad ulteriori analisi di classificazione e regressione.




\end{onecolabstract}
]

\tableofcontents

\section{Introduzione}
\label{sec:intro}

Il seguente progetto ha come obiettivo l'applicazione delle principali tecniche di analisi affrontate durante il corso \textit{Data Mining: Fundamentals}., utillizando un dataset (\textit{Board Game Geek (BGG)}) riguardante oltre 20{,}000  giochi da tavolo. Il dataset contiene moltissime feature per ogni gioco. 
Nella seguente sezione andremo ad introdurre le variabili che si studieranno durante lo svolgimento del progetto.

\subsection{Semantica dei dati}
\label{sec:semantica}

Ogni riga del \textit{dataset} corrisponde a un gioco da tavolo, identificato univocamente dal suo codice identificativo (\textit{BGGId, int}) e dal suo nome (\textit{Name, str}). 
Il campo \textit{Description} (\textit{str}) contiene una breve descrizione del gioco, fornita dalla comunità online di riferimento. 
L’attributo \textit{YearPublished} (\textit{int}) indica l’anno di pubblicazione del gioco, che per certi giochi antichi viene stimato.

\smallskip
Le complessità del gioco è descritta da due variabili: \textit{GameWeight} e \textit{ComWeight} (\textit{float, intervallo 1--5}), che rappresentano rispettivamente la complessità stimata e quella votata dalla comunità. 
Il numero di voti che hanno contribuito alla valutazione della complessità è fornito da \textit{NumWeightVotes} (\textit{int}). 
Altri attributi legati alla fruibilità includono il numero minimo e massimo di giocatori (\textit{MinPlayers, MaxPlayers, int}), l’età minima consigliata dalla comunità (\textit{ComAgeRec, float}) e il livello di competenza linguistica richiesta (\textit{LanguageEase, float}). 

\smallskip
Le variabili \textit{BestPlayers} (\textit{int}) e \textit{GoodPlayers} (\textit{lista di interi}) sintetizzano le preferenze espresse dalla comunità riguardo ai numeri consigliati di giocatori (\textit{GoodPlayers}) o il numero ideale  (\textit{BestPlayers}) di giocatori per ciascun gioco. 
Altre variabili descrivono la popolarità e la diffusione del gioco all’interno della piattaforma, come \textit{NumOwned}, \textit{NumWant} e \textit{NumWish} (\textit{int}), che indicano rispettivamente quanti utenti possiedono, desiderano o hanno aggiunto il gioco alla propria lista dei desideri.

\smallskip
Sono inoltre presenti variabili relative ai tempi di gioco: \textit{MfgPlayTime} (\textit{int}) rappresenta la durata media riportata dal produttore, mentre \textit{ComMinPlaytime} e \textit{ComMaxPlaytime} (\textit{int}) indicano le stime fornite dalla comunità. 
L’età consigliata dal produttore è fornita da \textit{MfgAgeRec} (\textit{int}). 

\smallskip
Ulteriori informazioni quantitative riguardano l’attività della community: \textit{NumUserRatings} e \textit{NumComments} (\textit{int}) riportano rispettivamente il numero di valutazioni e commenti ricevuti, mentre \textit{NumAlternates}, \textit{NumExpansions} e \textit{NumImplementations} (\textit{int}) indicano il numero di versioni alternative, espansioni e implementazioni collegate al gioco. 
Le variabili booleane \textit{IsReimplementation} e \textit{Kickstarted} (\textit{bool}) segnalano se il gioco rappresenta una reimplementazione di un altro titolo e se è stato finanziato tramite una campagna di \textit{crowdfunding}. 
La variabile \textit{Family} (\textit{str}) indica invece la famiglia ludica di appartenenza, quando disponibile. Un \textit{ImagePath (str)} viene fornito per poter accedere alla foto del gioco.

\smallskip
I giochi inoltre vengono divisi in otto categorie:  (\textit{Thematic, Strategy, War, Family, CGS, Abstract, Party, Childrens}) e vengono anche classificati rispetto a tutti gli altri giochi in base alla categoria (\textit{Rank:strategygames}, \textit{Rank:abstracts}, \textit{Rank:familygames}, \textit{Rank:thematic}, \textit{Rank:cgs}, \textit{Rank:wargames}, \textit{Rank:partygames} e \textit{Rank:childrensgames}). 

\smallskip
Infine, la variabile \textit{Rating} (\textit{Low, Medium, High}) rappresenta una classificazione generale del punteggio complessivo assegnato al gioco dalla comunity, distinguendo tra valutazioni basse, medie e alte.

\section{Preparazione e comprensione dei dati}

Date tutte queste variabili, il primo passo per iniziare a individuare relazioni interessanti nei dati consiste nel pulire il \textit{dataset}, con l’obiettivo di renderlo coerente e di facilitare le operazioni successive. 
Si è verificato che ogni colonna contenesse valori di un solo tipo, che la gestione degli zeri fosse corretta e che eventuali valori errati venissero eliminati. 
Infine, sono state combinate alcune colonne e rimosse quelle non utili ai fini dello studio del presente \textit{dataset}.

\subsection{Pulizia dei dati}
\label{sec:pulizia}

Come prima operazione, sono state eliminate le colonne \textit{ImagePath}, \textit{BGGId} e \textit{NumComments}, poiché non era di nostro interesse analizzare l’immagine del gioco, e il codice identificativo serviva unicamente a distinguere i giochi in modo univoco. 
È stato osservato che in alcuni casi rari (circa 420 su 22{,}000) diversi giochi da tavolo presentavano lo stesso nome; in tali casi, l’identificativo numerico sarebbe stato necessario per distinguerli. 
Tuttavia, poiché non si intende svolgere un’analisi sui singoli giochi, la presenza di questi duplicati non influisce sulla natura statistica dello studio, anche considerando che rappresentano meno del 2\% del \textit{dataset} complessivo.
La colonna \textit{NumComments}, contenente esclusivamente zeri, e quidni è stata rimossa.

\smallskip

Successivamente, si è intervenuti sulle colonne numeriche, decidendo di utilizzare \textit{NaN} come valore identificativo per i dati mancanti. 
Per le colonne in cui lo zero non è un valore ammesso dal dominio della variabile, tutti gli zeri e gli altri valori errati sono stati convertiti in \textit{NaN}. 
Più precisamente, le variabili \textit{GameWeight} e \textit{ComWeight} sono definite nell’intervallo $[1,5]$; pertanto, qualsiasi valore esterno a tale dominio è stato sostituito con \textit{NaN}. 
Le variabili \textit{ComAgeRec}, \textit{LanguageEase}, \textit{MfgPlaytime} e \textit{MfgAgeRec} possono assumere solo valori maggiori di zero, perciò gli zeri presenti sono stati sostituiti con \textit{NaN}.

\smallskip

Per le colonne \textit{MinPlayers}, \textit{MaxPlayers}, \textit{ComMinPlaytime} e \textit{ComMaxPlaytime}, è stato effettuato un controllo per verificare che il valore minimo fosse inferiore a quello massimo. In caso contrario, i due valori sono stati scambiati, e anche in questo caso gli zeri sono stati sostituiti con \textit{NaN}. 
Si è inoltre verificato che tutti i valori della lista \textit{GoodPlayers} fossero compresi nell’intervallo definito da \textit{MinPlayers} e \textit{MaxPlayers}, e che \textit{BestPlayers} fosse contenuto all’interno della lista \textit{GoodPlayers}. 
Ogni violazione di queste condizioni è stata sostituita con \textit{NaN}.

\smallskip

Le 16 colonne relative alle categorie e classificazioni dei giochi sono state condensate in una singola colonna vettoriale di lunghezza 8. 
In sintesi, a ciascun gioco è stato assegnato un vettore che rappresenta la sua classificazione in ognuna delle otto categorie. 
Se un gioco risultava classificato in posizione $21926$ (pari alla lunghezza del dataset), esso è stato considerato come non classificato e l’elemento corrispondente è stato posto a zero. Infatti, abbiamo verificato che ciò avviene solo quando un gioco non appartiene a quella categoria. 
Per le categorie di appartenenza, invece, il valore del \textit{ranking} è stato inserito come elemento del vettore. 
Questa strategia consente di considerare anche i giochi che appartengono a nessuna o a più categorie, senza perdita di generalità.

\smallskip

La colonna \textit{Description} è stata convertita in una lista di stringhe, separando parola per parola ed eliminando i duplicati. 
Infine, la colonna \textit{Rating} è stata trasformata in una colonna contenente solo i valori $\{-1, 0, 1\}$, mappando direttamente \textit{Low $\rightarrow$ -1}, \textit{Medium $\rightarrow$ 0} e \textit{High $\rightarrow$ 1}.


\subsection{Studio delle singole variabili}
\label{sec:studio_singole}
\subsubsection{Distribuzione delle colonne numeriche}
\label{sec:histos}

Come prima analisi, abbiamo studiato ciascun attributo numerico singolarmente, creando un istogramma per visualizzarne la distribuzione. 
Utilizzando il criterio di \textit{Sturges} per determinare il \textit{binning}, ci siamo accorti che, per la maggior parte delle colonne numeriche, la presenza di pochi \textit{outlier} dominava il grafico, rendendo gli istogrammi poco leggibili e ostacolando l’analisi dei dati. 
Per migliorare la qualità della visualizzazione, abbiamo deciso di calcolare i percentili ($5, 25, 50, 75, 95\%$) e di mantenere solo i dati compresi tra i percentili $5\%$ e $95\%$. 
Questo metodo si basa sulla tecnica dello \textit{scarto interquantile}, che rappresenta una statistica robusta rispetto agli \textit{outlier} per distribuzioni sufficientemente popolate, come nel nostro caso. 

Un esempio di distribuzione prima e dopo questa pulizia è mostrato in figura \ref{fig:histo_YearPublished}, dove nella colonna \textit{YearPublished} sono stati rimossi tutti i giochi pubblicati prima del $1978$ e dopo il $2020$, considerati \textit{outlier} secondo questa metrica. 
Solo il $7.88\%$ dei dati è stato rimosso, ma la leggibilità della distribuzione è migliorata in modo significativo. 

\begin{figure}[h]
\includegraphics[width=0.9\linewidth]{/histograms/all_data/analisi_singola_yearpublished.png}
\centering
\caption{Distribuzione della colonna \textit{YearPublished} prima e dopo la rimozione degli \textit{outlier} (considerando solo i valori compresi tra i percentili $5\%$ e $95\%$). Il \textit{binning} è stato scelto utilizzando il criterio di \textit{Sturges}.}
\label{fig:histo_YearPublished}
\end{figure}

Abbiamo svolto un’analisi analoga per tutte le colonne numeriche, creando un \textit{box plot} sovrapposto a un istogramma per i dati originali e ripetendo la procedura per i dati filtrati secondo il criterio descritto in precedenza (mantenendo solo i valori tra i percentili $5\%$ e $95\%$). 
La figura \ref{fig:histo_box_not_cleaned} riporta tutti gli istogrammi generati utilizzando i dati grezzi, mentre la figura \ref{fig:histo_box_cleaned} mostra gli stessi istogrammi dopo la pulizia applicata con il metodo discusso.

\begin{figure}[h]
\includegraphics[width=0.9\linewidth]{/histograms/all_data/Histogram_Matrix_all_data_unfiltered.png}
\centering
\caption{Distribuzioni delle variabili numeriche senza alcuna filtratura sul \textit{dataset} pulito. 
La visualizzazione è ottenuta tramite istogrammi sovrapposti a \textit{box plot}. 
I percentili corrispondono al $5, 25, 50, 75, 95\%$ dei dati originali. 
Il \textit{binning} è stato determinato utilizzando il criterio di \textit{Sturges}.}
\label{fig:histo_box_not_cleaned}
\end{figure}

\begin{figure}[h]
\includegraphics[width=0.9\linewidth]{/histograms/all_data/Histogram_Matrix_all_data_filtered.png}
\centering
\caption{Distribuzioni delle variabili singole dopo la rimozione degli \textit{outlier} (considerando solo i valori compresi tra i percentili $5\%$ e $95\%$). La visualizzazione è ottenuta tramite istogrammi sovrapposti a \textit{box plot}. I percentili corrispondono al $5, 25, 50, 75, 95\%$ dei dati filtrati. Il \textit{binning} è stato determinato utilizzando il criterio di \textit{Sturges}.}
\label{fig:histo_box_cleaned}
\end{figure}

Si osserva che la maggior parte delle distribuzioni presenta una forte asimmetria verso valori bassi, con un picco concentrato in prossimità del minimo. 
Più precisamente, i giochi più semplici (sia in termini di complessità del gioco sia di linguaggio) e con una durata più breve risultano più frequenti. 
Inoltre, i giochi che prevedono un numero ridotto di partecipanti (tipicamente da 2 a 4 giocatori) sono i più comuni, pur rimanendo superiori a uno, quindi non si tratta di giochi solitari. 
Questo suggerisce che, nel mondo dei giochi da tavolo, vengono prodotti più frequentemente titoli semplici e accessibili, che richiedono un numero relativamente basso di giocatori per essere apprezzati. 
Si nota inoltre che la maggior parte dei giochi è destinata a un pubblico di ragazzi tra gli 8 e i 12 anni.

\smallskip
Negli ultimi anni si osserva una crescita significativa del numero di giochi presenti nel \textit{dataset}, indicando che l’industria continua a espandersi. 
Nel 2020, tuttavia, si registra un calo rispetto all’anno precedente, probabilmente dovuto all’impatto della quarantena.

\smallskip
Per quanto riguarda le colonne \textit{booleane}, si nota che la maggior parte dei giochi non presenta implementazioni, versioni alternative o espansioni, e non è stata finanziata tramite campagne di \textit{crowdfunding}.  
Inoltre, la maggior parte dei giochi risulta posseduta da meno di mille persone (secondo i dati riportati nel \textit{dataset}). 
Le variabili legate all’\textit{engagement} degli utenti sul sito mostrano distribuzioni fortemente asimmetriche verso zero: \textit{NumWant}, \textit{NumWish} e \textit{NumWeightVotes} seguono tutte questo andamento, con la maggior parte dei valori inferiori al centinaio. 

Bisogna tenere conto del fatto che noi possiamo solo trarre conclusioni sui dati che abbiamo, e che il \textit{dataset} non è necessariamente descrittivo della realtà in maniera completa. Tuttavia, con questi dati si riescono comunque a trovare degli andamenti interessanti nelle singole colonne numeriche. 

\subsubsection{Distribuzione delle categorie}
\label{sec:categorie}

Abbiamo effettuato anche uno studio completo delle categorie dei giochi. 
Come prima analisi, abbiamo verificato quanti giochi appartengono a più di una categoria e quante categorie sono coinvolte in media. 
Questa informazione è riportata in figura \ref{fig:num_cats}, dove si osserva che la maggior parte dei giochi non è categorizzata oppure appartiene solo a una o due categorie.

\begin{figure}[h]
\includegraphics[width=0.9\linewidth]{/category_figures/distribuzione_numero_categorie_per_gioco.png}
\centering
\caption{Numero di categorie a cui appartiene ogni gioco, in scala logaritmica. Ogni gioco è stato contato una sola volta, indipendentemente dal numero di categorie al quale apparteneva.}
\label{fig:num_cats}
\end{figure}

Abbiamo inoltre analizzato la distribuzione delle singole categorie, contando quante volte ciascuna compare nel \textit{dataset}. 
I risultati sono mostrati in figura \ref{fig:distr_cats}. 
Si nota immediatamente che i giochi di guerra sono i più comuni, seguiti da quelli di strategia e da quelli di famiglia.

\begin{figure}[h]
\includegraphics[width=0.9\linewidth]{/category_figures/distribuzione_delle_categorie.png}
\centering
\caption{Distribuzione delle categorie di classificazione dei giochi.}
\label{fig:distr_cats}
\end{figure}

Successivamente, abbiamo studiato la distribuzione delle categorie prese a coppie. 
Ci siamo chiesti se esistesse una correlazione tra le categorie per i giochi che appartengono contemporaneamente a due di esse. 
Abbiamo quindi creato una \textit{heatmap} che visualizza il numero di co-occorrenze per ogni possibile coppia di categorie, mostrata in figura \ref{fig:heatmap_cats}. 
In questa figura, la diagonale rappresenta il numero totale di giochi appartenenti a ciascuna categoria singola, mentre gli elementi fuoir diagonale indicano il numero di giochi che condividono entrambe le categorie. 
La scala dei colori è stata impostata su base logaritmica, poiché i dati coprono diversi ordini di grandezza.

\begin{figure}[h]
\includegraphics[width=0.9\linewidth]{/category_figures/category_couples_heatmap.png}
\centering
\caption{Occorrenze delle varie coppie di categorie per i giochi appartenenti a due categorie. 
La diagonale rappresenta il numero di occorrenze della singola categoria. 
La scala dei colori è logaritmica.}
\label{fig:heatmap_cats}
\end{figure}

La figura \ref{fig:heatmap_cats} mostra solo il numero assoluto di co-occorrenze per ciascuna coppia; tuttavia, le categorie più popolose singolarmente (come \textit{war}, \textit{strategy} e \textit{family}) tendono naturalmente ad avere anche più co-occorrenze. 
Per tenere conto di questo effetto, abbiamo introdotto un fattore di normalizzazione definito come

\begin{equation}
	\centering
	M_{i,j}^\prime = \frac{M_{i,j}}{\sqrt{M_{i,i}\cdot M_{j,j}}}
	\label{eq:norm_cat}
\end{equation}

dove ogni elemento della matrice è normalizzato in base al numero di occorrenze delle categorie singole. 
Per costruzione, l’equazione (\ref{eq:norm_cat}) impone che la diagonale valga 1, mentre tutti gli elementi fuori diagonale risultino compresi normalizzati nell’intervallo $[0,1]$. 
La \textit{heatmap} normalizzata è mostrata in figura \ref{fig:heatmap_cats_norm}, dove la diagonale è stata eliminata (posta uguale a zero) per mettere in risalto i valori non banali.

\begin{figure}[h]
\includegraphics[width=0.9\linewidth]{/category_figures/category_couples_heatmap_norm.png}
\centering
\caption{Co-occorrenze normalizzate delle varie coppie di categorie per i giochi appartenenti a due categorie, secondo l’equazione (\ref{eq:norm_cat}). 
La diagonale è stata posta uguale a zero per chiarezza. 
I valori fuori diagonale perdono significatività dopo la normalizzazione e sono stati quindi omessi.}
\label{fig:heatmap_cats_norm}
\end{figure}

Dalla figura \ref{fig:heatmap_cats_norm} si osserva che la coppia \textit{strategy–family} rimane la più frequente, ma ora è evidente che ciò non è dovuto unicamente all’elevata numerosità delle due categorie. 
Si nota inoltre che, mentre nel conteggio grezzo le coppie \textit{family–party} e \textit{thematic–war} presentavano quasi lo stesso numero di co-occorrenze ($156$ e $157$ rispettivamente), la coppia \textit{family–party} risulta più correlata una volta tenuto conto del numero molto elevato di giochi di guerra presenti nel \textit{dataset}. 

\smallskip
Non abbiamo analizzato le co-occorrenze tra tre o più categorie poiché un numero trascurabile di giochi appartiene contemporaneamente a tre categorie, come già mostrato in figura \ref{fig:num_cats}. 

\smallskip
Nel complesso, le figure \ref{fig:num_cats}, \ref{fig:distr_cats}, \ref{fig:heatmap_cats} e \ref{fig:heatmap_cats_norm} forniscono un quadro completo della distribuzione e delle correlazioni tra le categorie dei giochi da tavolo.

\subsubsection{Distribuzione delle descrizioni}
\label{sec:distro_descriz}
Infine, abbiamo studiato la distribuzione delle descrizioni dei giochi. Dopo aver convertito ogni colonna in una lista di stringhe, e assicurandoci che ogni parola comparisse una sola volta per lista, abbiamo creato un grafico a barre per visualizzare le occorrenze delle parole singole. Questo grafico si vede in figura \ref{fig:top_words}.

\begin{figure}[h]
\includegraphics[width=0.9\linewidth]{/top_words/occorrenza_delle_parole_più_usate_nelle_descrizioni.png}
\centering
\caption{Grafico a barre delle occorrenze delle singole parole nella colonna \textit{Descriptions} del dataset.
Ci siamo assicurarti di eliminare le occorrenze doppie delle parole.}
\label{fig:top_words}
\end{figure}

Non ci sorprende che le parole più comuni nelle descrizioni sono "game", "player", "win", "turn", e altre parole simili che si riferiscono ad un gioco in generale.

\subsection{Studio delle variabili a coppia}
\label{sec:coppie}
Avendo studiato gli attributi dei giochi singolarmente, il prossimo passo nella nostra comprensione del \textit{dataset} è di analizzare le colonne numeriche due a due, generando vari \textit{scatterplots} e matrici di correlazione per identificare pattern che ci potrebbero essere sfuggiti nell'analisi precedente. 

\subsubsection{Visualizzazione delle coppie di variabili}
\label{sec:scatters}

Come primo passo, abbiamo generato un insieme di \textit{scatterplot} per alcune colonne numeriche. 
Abbiamo escluso le variabili \textit{booleane}, come \textit{IsReimplementation}, \textit{Kickstarted} e \textit{Rating}, e quelle con varianza molto bassa, come \textit{MinPlayers}, \textit{MaxPlayers}, \textit{BestPlayers}, \textit{GoodPlayers}, \textit{NumImplementations}, \textit{NumExpansions}, \textit{NumAlternates} e \textit{NumWeightVotes}. 
Queste colonne, assumendo pochi valori discreti, non sono adatte a essere rappresentate tramite \textit{scatterplot}; pertanto, per ridurre la dimensione dell’insieme di grafici, non sono state confrontate con le altre. 
La figura \ref{fig:scatter_unfiltered} mostra tutte le coppie tra le variabili numeriche rimanenti, considerando ciascuna combinazione una sola volta.

\begin{figure}[h]
\includegraphics[width=0.9\linewidth]{/scatterplots/all_data/Scatterplots_all_data_unfiltered}
\centering
\caption{\textit{Scatterplot} delle variabili numeriche di interesse. 
I dati non sono stati filtrati in alcun modo e ogni coppia compare una sola volta.}
\label{fig:scatter_unfiltered}
\end{figure}

Utilizzando lo stesso criterio di pulizia dei dati discusso nella sezione \ref{sec:histos} (basato sulla rimozione dei valori al di fuori dei percentili $5\%$ e $95\%$), abbiamo generato un secondo insieme di \textit{scatterplot} utilizzando i dati depurati dagli \textit{outlier}. 
Questo consente di visualizzare meglio le zone più dense e centrali delle distribuzioni, come mostrato in figura \ref{fig:scatter_filtered}.

\begin{figure}[h]
\includegraphics[width=0.9\linewidth]{/scatterplots/all_data/Scatterplots_all_data_filtered}
\centering
\caption{\textit{Scatterplot} delle variabili numeriche di interesse. 
I dati sono stati filtrati rimuovendo i valori al di fuori dei percentili più esterni ($5\%$ e $95\%$). 
Ogni coppia compare una sola volta.}
\label{fig:scatter_filtered}
\end{figure}

La maggior parte delle coppie di variabili risulta distribuita in modo apparentemente scorrelato, con punti distribuiti uniformemente sul piano. 
Alcune coppie, tuttavia, mostrano una chiara correlazione positiva, evidenziata da un andamento lineare nei rispettivi \textit{scatterplot}. 
Queste correlazioni verranno discusse più nel dettaglio nella prossima sezione (\ref{sec:correlazioni}), ma già da ora si può osservare una correlazione quasi 1:1 tra \textit{ComWeight} e \textit{GameWeight}.

\subsubsection{Correlazione tra coppie di variabili}
\label{sec:correlazioni}

Per approfondire quanto osservato nella sezione precedente, abbiamo creato una \textit{heatmap} basata sull’indice di correlazione di Pearson tra le variabili considerate. 
Il criterio di selezione delle colonne numeriche è lo stesso adottato nella sezione \ref{sec:scatters}. 
La \textit{heatmap} di correlazione è mostrata in figura \ref{fig:heatmap_corr}.

\begin{figure}[h]
\includegraphics[width=0.9\linewidth]{/heatmaps/correlation_heatmap_unfiltered.png}
\centering
\caption{Matrice di correlazione tra le colonne numeriche analizzate. 
I dati non sono stati filtrati in alcun modo.}
\label{fig:heatmap_corr}
\end{figure}

Come di consueto, abbiamo applicato il nostro criterio di filtraggio basato sulla tecnica descritta nelle sezioni precedenti, e il risultato della pulizia è riportato in figura \ref{fig:heatmap_corr_filt}.

\begin{figure}[h]
\includegraphics[width=0.9\linewidth]{/heatmaps/correlation_heatmap_filtered.png}
\centering
\caption{Matrice di correlazione tra le colonne numeriche analizzate. 
I dati sono stati filtrati rimuovendo i valori al di fuori dei percentili più esterni ($5\%$ e $95\%$).}
\label{fig:heatmap_corr_filt}
\end{figure}

Come anticipato, la correlazione tra \textit{ComWeight} e \textit{GameWeight} risulta massima nell’indice di Pearson. 
Questo risultato non sorprende, poiché entrambe le variabili rappresentano due stime della stessa misura e sono quindi strettamente correlate. 
Di conseguenza, qualsiasi variabile correlata a una di esse risulterà correlata anche all’altra nello stesso modo.

\smallskip 
Un comportamento analogo si osserva tra \textit{ComAgeRec} e \textit{MfgAgeRec}, che rappresentano rispettivamente l’età consigliata dalla comunità e quella proposta dal produttore; anche in questo caso la correlazione è praticamente 1:1. 

Le variabili \textit{NumUserRatings} e \textit{NumOwned} sono fortemente correlate, poiché un utente può lasciare una valutazione solo per un gioco che possiede. 
Analogamente, \textit{NumWish} e \textit{NumWant} risultano strettamente correlate, in quanto entrambe misurano l’interesse dell’utenza verso un gioco. 

Infine, \textit{ComMaxPlaytime} e \textit{MfgPlaytime} sono anch’esse fortemente correlate, suggerendo che i produttori tendono a utilizzare il tempo massimo di gioco stimato dalla comunità come riferimento per la durata indicata ufficialmente.

\smallskip
In tutti questi casi, le correlazioni derivano dal fatto che le variabili rappresentano misure equivalenti o strettamente connesse dello stesso concetto. 
Pertanto, ai fini dell’analisi, tali variabili possono essere considerate ridondanti. 
Per ridurre la dimensionalità e mettere meglio in evidenza le altre relazioni, abbiamo rimosso le variabili \textit{ComWeight}, \textit{ComAgeRec}, \textit{NumUserRatings}, \textit{MfgPlaytime} e \textit{NumWish}. 
La nuova matrice di correlazione è riportata in figura \ref{fig:heatmap_corr_filt_dim}.

\begin{figure}[h]
\includegraphics[width=0.9\linewidth]{/heatmaps/correlation_heatmap_filtered_diminished.png}
\centering
\caption{Matrice di correlazione tra le colonne numeriche analizzate, dopo la rimozione di una variabile per ciascuna coppia correlata 1:1. 
I dati sono stati filtrati rimuovendo i valori al di fuori dei percentili più esterni ($5\%$ e $95\%$).}
\label{fig:heatmap_corr_filt_dim}
\end{figure}

Dopo la pulizia del \textit{dataset}, emergono nuove correlazioni precedentemente nascoste dagli \textit{outlier}. 
Ad esempio, si osserva una relazione positiva tra la complessità del gioco, il tempo di gioco e l’età consigliata. 
Questo risultato è intuitivo: i giochi più complessi tendono a richiedere più tempo e sono destinati a un pubblico più maturo. 
Di conseguenza, si evidenzia una correlazione diretta tra età e durata del gioco.

Anche il tempo minimo e quello massimo di gioco risultano fortemente correlati: per definizione il tempo massimo deve essere maggiore del minimo, ma l’intensità della correlazione suggerisce che i giochi più lunghi presentano in generale tempi elevati in entrambe le misure.

Infine, il numero di utenti che desiderano un gioco (\textit{NumWant}) è positivamente correlato con il numero di utenti che lo possiedono (\textit{NumOwned}). 

\smallskip
Queste ultime correlazioni, pur non essendo perfettamente 1:1, forniscono comunque informazioni utili sulla struttura del \textit{dataset}. 
Esse mostrano, ad esempio, come alcuni valori riportati dai produttori riflettano direttamente le stime fornite dalla comunità - come nel caso del tempo di gioco indicato, fortemente correlato con il tempo massimo riportato dagli utenti - e come diversi indicatori di popolarità descrivano aspetti complementari dello stesso fenomeno.
\subsection{Preparazione finale dei dati}
\label{sec:prep}

Ora che abbiamo compreso il comportamento generale dei dati, vogliamo intervenire sul \textit{dataset} per renderlo più leggero, coerente e analizzabile. 
Sono state quindi applicate tecniche di aggregazione per ridurre il numero di colonne, di \textit{sampling} per diminuire il numero di righe e trasformazioni di variabili per migliorarne la compatibilità e l’interpretabilità.

\smallskip

L’intero \textit{dataset} è stato filtrato rimuovendo, da ogni colonna numerica, i valori considerati \textit{outlier}, utilizzando il consueto metodo di selezione: sono stati eliminati tutti i valori al di fuori dei percentili $5\%$ e $95\%$.

\subsubsection{Aggregazione dei dati}
\label{sec:aggr}

Come primo passo nella fase di preparazione finale del \textit{dataset}, abbiamo utilizzato i risultati ottenuti nella sezione \ref{sec:correlazioni} per identificare quali attributi fossero ridondanti in base alla loro correlazione reciproca. 
Come già discusso, sono state individuate quattro coppie di variabili altamente correlate: \textit{ComAgeRec} e \textit{MfgAgeRec}, \textit{NumWish} e \textit{NumWant}, \textit{ComWeight} e \textit{GameWeight}, e infine \textit{MfgPlaytime} e \textit{ComMaxPlaytime}. 
Data l’elevata correlazione tra le variabili di ciascuna coppia, abbiamo applicato una \textit{Principal Component Analysis (PCA)} per sostituire ogni coppia con una singola colonna che ne descrivesse la tendenza principale. 
Le nuove colonne sono state denominate \textit{AgeRec}, \textit{NumDesires}, \textit{Weight} e \textit{Playtime}, rispettivamente. 
In questo modo, otto colonne sono state aggregate in quattro.\footnote{Poiché la correlazione tra le coppie di variabili è prossima a 1, si potrebbe anche eliminare una delle due colonne e mantenere l’altra. Tuttavia, l’approccio con PCA evita una scelta arbitraria e rende l’analisi più generale.}
Tutte le nuove colonne sono state normalizzate tramite \textit{min–max scaling}, riportando i valori nell’intervallo $[0,1]$.

\smallskip
Un’altra coppia di variabili fortemente correlate è costituita da \textit{NumUserRatings} e \textit{NumOwned}. 
Invece di applicare nuovamente la \textit{PCA}, abbiamo scelto di aggregarle tramite una trasformazione che combinasse l’informazione contenuta in entrambe. 
Per ottenere una stima del \textit{rating} pesata in base al numero di voti, abbiamo impiegato la tecnica del \textit{Bayesian shrinkage}, comunemente utilizzata da siti che classificano film, giochi o prodotti in base alle valutazioni degli utenti. 
La formula utilizzata è la seguente:

\begin{equation}
	\text{score} = \frac{n \cdot s + m \cdot \sigma}{n + m}
	\label{eq:weighted_score}
\end{equation}

dove $n$ rappresenta il numero di voti, $s$ il punteggio del gioco ($\{-1, 0, 1\}$), $m$ il numero medio di voti e $\sigma$ la media globale del punteggio su tutto il \textit{dataset}. 
Abbiamo quindi sostituito le colonne \textit{NumUserRatings} e \textit{NumOwned} con una singola colonna, denominata \textit{WeightedRatings}, riducendo la dimensionalità del \textit{dataset} e, allo stesso tempo, arricchendo l’informazione contenuta nella variabile \textit{Rating}. 
Anche questa colonna è stata infine normalizzata nell’intervallo $[0,1]$ tramite \textit{min–max scaling}.

\smallskip

Infine, la colonna \textit{LanguageEase} è stata trasformata applicando una funzione logaritmica, per rendere la distribuzione più simmetrica, e successivamente normalizzata nell’intervallo $[0,1]$ con \textit{min–max scaling}.  
Le distribuzioni delle colonne trasformate e aggregate sono mostrate in figura \ref{fig:histoboxmatrix_transformed}.

\begin{figure}[h]
\includegraphics[width=0.9\linewidth]{/columns_transformed/all_data/histo_box_matrix_transformed_all_data.png}
\centering
\caption{Distribuzioni delle variabili numeriche trasformate e aggregate. 
La visualizzazione è ottenuta tramite istogrammi sovrapposti a \textit{box plot}. 
I percentili corrispondono al $5, 25, 50, 75, 95\%$ dei dati originali. 
Il \textit{binning} è stato determinato utilizzando il criterio di \textit{Sturges}.}
\label{fig:histoboxmatrix_transformed}
\end{figure}

Come si può osservare, le distribuzioni risultano ora più centralizzate e leggibili, permettendo di analizzare con maggiore chiarezza l’andamento delle variabili, pur avendo ridotto la dimensionalità complessiva del \textit{dataset}.

\subsubsection{Sampling}
\label{sec:sampl}

Come prossimo passo, abbiamo deciso di implementare delle tecniche di \textit{sampling} per ridurre la quantità di dati con lo scopo di perdere il numero minimo di informazione. Abbiamo usato un \textit{random sampling}, selezionando randomicamente con rimozione da tutte le righe possibile, con una probabilità uniforme per ogni riga. Abbiamo confrontato la distribuzione di alcune colonne \textit{sampled} randomicamente con $2000$ righe rispetto a no sampling. Si vede in figura \ref{fig:sampling_comparison_agerec} il confronto tra la distribuzione della colonna \textit{AgeRec} prima e dopo del \textit{sampling}.


\begin{figure}[h]
\includegraphics[width=0.9\linewidth]{/sampling/all_data/AgeRec_histogram_comparison.png}
\centering
\caption{Distribuzione della colonna \textit{AgeRec} prima e dopo del \textit{sampling} randomico.
Sono stati presi \textit{2000} righe randomiche, con rimozione. 
Il \textit{binning} è stato determinato utilizzando il criterio di \textit{Sturges}.}
\label{fig:sampling_comparison_agerec}
\end{figure}

Come si vede in figura, i percentili dei dati sono rimasti per lo più inalterati, e la forma della distribuzione rimane simile. Questo ci dimostra che un \textit{sampling} randomico può essere un'ottimo metodo per ridurre la quantità di dati pur mantenedo le caratteristiche importanti della distribuzione, almeno per quanto riguarda $2000$ \textit{samples}. 
\section{Clustering}
\label{sec:clustering}

Nel trattamento del \textit{dataset} abbiamo applicato diverse tecniche di \textit{clustering} per cercare relazioni tra coppie di variabili. Sono stati utilizzati vari metodi, tra cui \textit{density-based clustering}, \textit{k-means} (analizzando anche il variare della \textit{SSE} al variare di $k$) e \textit{hierarchical clustering}. 
L’analisi si è concentrata principalmente sulla relazione tra \textit{WeightedRating} e \textit{NumDesires}, e tra \textit{WeightedRating} e \textit{AgeRec}.

\subsection{Density-based}
\label{sec:density}

Come prima analisi abbiamo utilizzato un algoritmo di \textit{density-based clustering}, come mostrato nelle figure \ref{fig:db_numdes_weightedr} e \ref{fig:db_weightedr_agerec}. 
Tutte le analisi sono state eseguite sul \textit{dataset} filtrato e sottoposto a \textit{sampling} a $2000$ righe. I valori \textit{NaN} sono stati rimossi.

\begin{figure}[h]
\includegraphics[width=0.9\linewidth]{../static_images/numdesires_vs_weightedrating/dbscan_numdesires_vs_weightedrating.png}
\centering
\caption{Density-based clustering di weighted rating vs numdesires}
\label{fig:db_numdes_weightedr}
\end{figure}

\begin{figure}[h]
\includegraphics[width=0.9\linewidth]{../static_images/weightedrating_vs_agerec/dbscan_weightedrating_vs_agerec.png}
\centering
\caption{Density-based clustering di weighted rating vs agerec}
\label{fig:db_weightedr_agerec}
\end{figure}

Come si osserva, i \textit{clusters} individuati non riportano informazioni particolarmente significative, suggerendo che questa tecnica non sia la più adatta allo studio di queste variabili. 
Tuttavia, tra le varie coppie analizzate, queste presentavano i \textit{clusters} più separati e interpretabili. 
Per esempio, in figura \ref{fig:db_weightedr_agerec} si nota un cluster che copre valori medi di \textit{WeightedRating} per quasi tutte le età considerate. Questo suggerisce che esistono giochi valutati in maniera neutra indipendentemente dalla fascia d’età, mentre altri giochi — pensati per categorie di età più specifiche — presentano valutazioni differenti, come mostrato dagli altri \textit{clusters}.

\subsection{K-means}
\label{sec:kmeans}

Abbiamo poi effettuato un’analisi analoga utilizzando l’algoritmo di \textit{k-means clustering}. Come riportato nelle figure \ref{fig:kmeans_numdes_weightedr} e \ref{fig:kmeans_weightedr_agerec}, abbiamo fissato $k=4$.

\begin{figure}[h]
\includegraphics[width=0.9\linewidth]{../static_images/numdesires_vs_weightedrating/k_means_numdesires_vs_weightedrating.png}
\centering
\caption{K-means clustering weighted rating vs numdesires, 4 \textit{clusters}}
\label{fig:kmeans_numdes_weightedr}
\end{figure}

\begin{figure}[h]
\includegraphics[width=0.9\linewidth]{../static_images/weightedrating_vs_agerec/k_means_weightedrating_vs_agerec.png}
\centering
\caption{K-means clustering weighted rating vs agerec, 4 \textit{clusters}}
\label{fig:kmeans_weightedr_agerec}
\end{figure}

In questo caso i \textit{clusters} si separano in base alla fascia d’età (figura \ref{fig:kmeans_weightedr_agerec}) o principalmente in base al punteggio pesato (figura \ref{fig:kmeans_numdes_weightedr}). 
Inoltre, diversamente dagli algoritmi basati sulla densità, il metodo \textit{k-means} non gestisce il rumore: i punti che prima venivano classificati come rumore vengono forzati in uno dei \textit{clusters}.

\smallskip

È stato inoltre studiato l’andamento della \textit{Sum Squared Error (SSE)} al variare di $k$. I risultati sono mostrati in figura \ref{fig:sse_numdes_weightedr} e \ref{fig:sse_weightedr_agerec}, e sono il criterio utilizzato per fissare il valore ottimale di $k$ nelle figure precedenti.

\begin{figure}[h]
\includegraphics[width=0.9\linewidth]{../static_images/numdesires_vs_weightedrating/sse_vs_k_numdesires_vs_weightedrating.png}
\centering
\caption{SSE del K-means clustering weighted rating vs numdesires, al variare di \textit{k}}
\label{fig:sse_numdes_weightedr}
\end{figure}

\begin{figure}[h]
\includegraphics[width=0.9\linewidth]{../static_images/weightedrating_vs_agerec/sse_vs_k_weightedrating_vs_agerec.png}
\centering
\caption{SSE del K-means clustering weighted rating vs agerec, al variare di \textit{k}}
\label{fig:sse_weightedr_agerec}
\end{figure}

Come atteso, la \textit{SSE} diminuisce all’aumentare del numero di centroidi, e le figure confermano questo andamento. 
Per evitare \textit{overfitting}, abbiamo scelto $k=4$, corrispondente al punto di “gomito” della curva.

\subsection{Hierarchical clustering}
\label{sec:hierarchical}

Come ultima tecnica, abbiamo applicato l’\textit{hierarchical clustering} alle stesse variabili considerate finora. I risultati sono riportati nelle figure \ref{fig:hie_numdes_weightedr} e \ref{fig:hie_weightedr_agerec}.

\begin{figure}[h]
\includegraphics[width=0.9\linewidth]{../static_images/numdesires_vs_weightedrating/hierarchical_numdesires_vs_weightedrating.png}
\centering
\caption{Hierarchical clustering weighted rating vs numdesires}
\label{fig:hie_numdes_weightedr}
\end{figure}

\begin{figure}[h]
\includegraphics[width=0.9\linewidth]{../static_images/weightedrating_vs_agerec/hierarchical_weightedrating_vs_agerec.png}
\centering
\caption{Hierarchical clustering weighted rating vs agerec}
\label{fig:hie_weightedr_agerec}
\end{figure}

I risultati ottenuti non sono molto soddisfacenti, tuttavia modificando leggermente i parametri è stato possibile ottenere una clusterizzazione più efficace:

\begin{figure}[h]
	\includegraphics[width=0.9\linewidth]{../static_images/hierarchical_numdesires_vs_weightedrating_average.png}
	\centering
	\caption{Hierarchical clustering weighted rating vs agerec}
	\label{fig:hie_weightedr_agerec}
\end{figure}

Dall’immagine emergono cinque cluster ben distinti: in azzurro compaiono i giochi poco apprezzati e poco desiderati; in giallo quelli mediamente valutati ma con scarso interesse da parte degli utenti (la categoria più numerosa); in viola i giochi molto desiderati ma con valutazioni nella media, come titoli minori diventati popolari grazie alla notorietà della casa produttrice o varianti meno riuscite; in rosa i giochi ben valutati ma poco desiderati, magari titoli di nicchia molto apprezzati; infine, in verde, i giochi più popolari e meglio valutati.

Sono inoltre riportati i rispettivi \textit{dendrogram} in figure \ref{fig:ddg_numdes_weightedr} e \ref{fig:ddg_weightedr_agerec}.

\begin{figure}[h]
\includegraphics[width=0.9\linewidth]{../static_images/numdesires_vs_weightedrating/dendrogram_numdesires_vs_weightedrating.png}
\centering
\caption{Dendrogram dell’hierarchical clustering weighted rating vs numdesires}
\label{fig:ddg_numdes_weightedr}
\end{figure}

\begin{figure}[h]
\includegraphics[width=0.9\linewidth]{../static_images/weightedrating_vs_agerec/dendrogram_weightedrating_vs_agerec.png}
\centering
\caption{Dendrogram dell’hierarchical clustering weighted rating vs agerec}
\label{fig:ddg_weightedr_agerec}
\end{figure}

Osservando i diagrammi ad albero, si nota come la scelta di suddividere le due coppie di categorie in 4-5 cluster risulti appropriata: tracciando una linea orizzontale sull’albero è infatti possibile ottenere una suddivisione significativa dell’intero set di dati.

\section{Classificazione}
\label{sec:classification}

Come passo successivo abbiamo utilizzato diverse tecniche di classificazione con lo scopo di prevedere il possibile \textit{rating} di un gioco a partire dai suoi attributi. Abbiamo esplorato sia tecniche \textit{lazy}, come la classificazione \textit{KNN}, sia tecniche \textit{eager}, come \textit{Naive Bayes} e \textit{Decision Trees}. L’analisi si è concentrata principalmente sulla classificazione della colonna \textit{Rating} utilizzando come \textit{feature} le coppie \textit{AgeRec}-\textit{Weight} e \textit{NumDesires}-\textit{YearPublished}.

Per tutti gli algoritmi di classificazione, il \textit{dataset} è stato suddiviso in due parti: il $70\%$ dei dati è stato utilizzato per il \textit{training} dei modelli, mentre il restante $30\%$ è stato riservato come \textit{dataset} di test. La suddivisione è stata effettuata in modo randomico, al fine di ridurre possibili effetti di \textit{bias} e garantire che entrambe le parti rappresentassero adeguatamente l’interezza dei dati.

\subsection{Classificazione KNN}

Abbiamo iniziato utilizzando il metodo di classificazione basato sui primi \textit{k} vicini, ovvero la classificazione \textit{KNN}, per stimare il \textit{Rating} utilizzando \textit{NumDesires} e \textit{YearPublished} come \textit{feature}.

Prima di applicare l’algoritmo, abbiamo rimosso tutte le righe contenenti valori \textit{NaN} ed effettuato una standardizzazione basata sullo \textit{Z-score}, che porta le \textit{feature} ad avere media nulla e deviazione standard unitaria. Questa operazione è necessaria in quanto l’algoritmo si basa sulla distanza euclidea, e quindi è necessario che le variabili siano confrontabili sulla stessa scala. In questo modo, colonne come \textit{YearPublished} e \textit{NumDesires} contribuiscono in maniera bilanciata alla metrica Euclideaanza, evitando che una \textit{feature} domini rispetto alle altre.

\subsubsection{Selezione del parametro \textit{k}}

Per individuare il valore ottimale di \textit{k}, abbiamo calcolato l’accuratezza del modello al variare di questo parametro utilizzando una \textit{10-fold cross validation} e mediando i risultati ottenuti. L’accuratezza è stata calcolata come il rapporto tra il numero di predizioni corrette (veri positivi e veri negativi per ciascuna classe) e il numero totale di osservazioni.

Questa procedura consente di ottenere una stima più robusta delle prestazioni del modello, riducendo la dipendenza dalla particolare suddivisione tra \textit{training} e \textit{test set}.

\begin{figure}[h]
	\includegraphics[width=0.9\linewidth]{../figures/classification/KNN/NumDesires_YearPublished/KNN_K_Search_Accuracy_Rating.png}
	\centering
	\caption{Accuratezza in funzione di \textit{k}, calcolata tramite \textit{10-fold cross-validation}, con \textit{k} variabile tra $1$ e $96$ in passi di $5$. Si osserva che $k=26$ massimizza l’accuratezza del modello.}
	\label{fig:k_sel_class_ND_YP}
\end{figure}

Come mostrato in figura \ref{fig:k_sel_class_ND_YP}, il valore $k=26$ corrisponde alla massima accuratezza media. Di conseguenza, questo valore è stato utilizzato nelle analisi successive.

\subsubsection{Analisi del modello}

Dopo aver preparato i dati e selezionato il valore ottimale del parametro, abbiamo eseguito l’algoritmo di classificazione \textit{KNN} con $k=26$. Come prima analisi delle prestazioni, abbiamo esaminato la matrice di confusione ottenuta applicando il modello ai dati di \textit{test}, riportata in figura \ref{fig:confusion_matrix_ND_YP}.

\begin{figure}[h]
	\includegraphics[width=0.9\linewidth]{../figures/classification/KNN/NumDesires_YearPublished/KNN_Confusion_Matrix_Rating.png}
	\centering
	\caption{Matrice di confusione per il target \textit{Rating}, utilizzando \textit{NumDesires} e \textit{YearPublished} come \textit{feature}.}
	\label{fig:confusion_matrix_ND_YP}
\end{figure}

Dalla matrice di confusione si osserva che accuratezza, precisione e richiamo si trovano intorno al $59\%$. A titolo di confronto, un classificatore che selezionasse casualmente una delle tre classi di \textit{Rating} otterrebbe un’accuratezza attesa di circa il $33\%$. Il modello risulta quindi significativamente migliore di una scelta casuale. Tuttavia, ci suggerisce che non riesca a spiegare completamente la variabilità del \textit{Rating} tramite queste sole \textit{feature}. 

Si nota inoltre che la classe $-1$ viene confusa meno frequentemente con la classe $1$ rispetto alla classe $0$, indicando che giochi con valutazioni estremamente positive o negative risultano più facilmente distinguibili rispetto a quelli con valutazione intermedia, che non ci sorprende come risultato.

Per valutare la separabilità delle classi, abbiamo costruito le \textit{ROC curve} per ciascuna classe del target, considerando le altre due come classe negativa. A partire da queste curve abbiamo calcolato l’\textit{AUC (Area Under Curve)} come metrica di valutazione. La \textit{ROC curve} rappresenta il compromesso tra il tasso di veri positivi e quello di falsi positivi al variare della soglia di classificazione.

\begin{figure}[h]
	\includegraphics[width=0.9\linewidth]{../figures/classification/KNN/NumDesires_YearPublished/KNN_Combined_ROC_Rating.png}
	\centering
	\caption{\textit{ROC curve} per il target \textit{Rating} utilizzando \textit{NumDesires} e \textit{YearPublished}. La linea tratteggiata rappresenta un classificatore casuale privo di potere discriminante.}
	\label{fig:ROC_ND_YP}
\end{figure}

Come mostrato in figura \ref{fig:ROC_ND_YP}, la classe $-1$ risulta la più facilmente distinguibile ($AUC = 0.82$), mentre la classe $0$ è la più difficile da separare ($AUC = 0.65$). Questo è coerente con l’interpretazione del \textit{Rating} medio come classe di transizione tra valutazioni positive e negative.

Tuttavia, la \textit{ROC curve} non fornisce informazioni sulla distribuzione delle classi. Per completare l’analisi del modello abbiamo quindi considerato anche le \textit{precision-recall curves}, costruite ordinando le predizioni sul \textit{dataset} di test e valutando precisione e richiamo al variare della soglia di classificazione. 

\begin{figure}[h]
	\includegraphics[width=0.9\linewidth]{../figures/classification/KNN/NumDesires_YearPublished/KNN_Combined_Precision_Recall_Rating.png}
	\centering
	\caption{\textit{Precision-recall curve} per il target \textit{Rating} utilizzando \textit{NumDesires} e \textit{YearPublished}.}
	\label{fig:P_R_ND_YP}
\end{figure}

I risultati, riportati in figura \ref{fig:P_R_ND_YP}, mostrano che la classe $1$, pur presentando una buona \textit{AUC} nella \textit{ROC curve}, perde rapidamente precisione all’aumentare del richiamo. Questo comportamento è dovuto al fatto che si tratta della classe meno popolata: per individuare un numero maggiore di giochi con \textit{Rating} alto è necessario accettare una precisione inferiore rispetto alle altre classi.

\subsection{Naive Bayes}

Come algoritmo successivo abbiamo utilizzato il \textit{Naive Bayes}, con l’obiettivo di classificare il \textit{Rating} di un gioco a partire da un insieme di \textit{feature}. Poiché il \textit{Naive Bayes} è particolarmente adatto anche alla gestione di \textit{feature} categoriche, abbiamo incluso la variabile \textit{Family} come attributo aggiuntivo, insieme a \textit{NumDesires} e \textit{YearPublished}. 

Come nel caso precedente, abbiamo iniziato rimuovendo dal \textit{dataset} tutte le righe contenenti valori \textit{NaN} e standardizzando le variabili numeriche per portarle ad avere media nulla e deviazione standard unitaria. Questo implica che l’analisi è stata condotta esclusivamente sui giochi appartenenti ad almeno una famiglia: i giochi non appartenenti a nessuna famiglia sono trattati come \textit{NaN} e quindi rimossi. Perciò, l’analisi è stata effettuata su circa il $30\%$ del \textit{dataset} iniziale, limitandosi ai soli giochi associati ad una famiglia.

Abbiamo utilizzato il modello \textit{MixedNB} del pacchetto \textit{mixed-naive-bayes}, estensione di \textit{scikit-learn}, che tratta le \textit{feature} numeriche come variabili gaussiane e utilizza una \textit{likelihood} multibernoulliana per le \textit{feature} categoriche. A ciascuna categoria è stata assegnata una chiave numerica tramite \textit{ordinal encoding}. Come per la classificazione \textit{KNN}, abbiamo analizzato le prestazioni del modello tramite matrice di confusione, \textit{ROC curves} e curve di precisione-richiamo. Tutti i risultati sono riportati in figura \ref{fig:dashboard_NB}.

\begin{figure}[h]
	\includegraphics[width=0.9\linewidth]{../figures/classification/NB/NB_Full_Summary_Report_Rating.png}
	\centering
	\caption{Matrice di confusione, \textit{ROC curves} e curve di precisione-richiamo per il target \textit{Rating}, utilizzando \textit{NumDesires} e \textit{YearPublished} come \textit{feature} numeriche e \textit{Family} come \textit{feature} categorica.}
	\label{fig:dashboard_NB}
\end{figure}

Analogamente al caso del \textit{KNN}, accuratezza, precisione e richiamo indicano che il modello classifica correttamente i dati con una frequenza significativamente maggiore rispetto a un classificatore casuale. Anche in questo caso, la classe più difficile da classificare risulta essere la classe $0$, in quanto intermedia tra le altre due. Tutte le metriche risultano complessivamente migliori rispetto a quelle ottenute con il \textit{KNN}, suggerendo che l’inclusione della variabile \textit{Family} abbia fornito informazione aggiuntiva utile alla classificazione.

Tuttavia, l’introduzione di questa \textit{feature} comporta una restrizione del \textit{dataset} analizzato, introducendo un \textit{bias} a priori: il modello viene infatti addestrato e valutato esclusivamente sui giochi appartenenti a una famiglia, e non sull’interezza del \textit{dataset} originale.

Infine, è importante ricordare che il \textit{Naive Bayes} assume l’indipendenza condizionata tra le \textit{feature}. Sebbene le variabili considerate non presentino forti correlazioni, non possono essere considerate completamente indipendenti. Nonostante questa limitazione, la tecnica del \textit{Naive Bayes} si è dimostrata robusta e particolarmente utile, permettendo di integrare efficacemente \textit{feature} numeriche e categoriche all’interno del processo di classificazione.


\subsection{Decision Trees}
12345678

\section{Regressione}

Come ulteriore strumento di predizione abbiamo studiato la dipendenza tra le colonne utilizzando tecniche di regressione. Non ci siamo limitati alla banale regressione lineare, svolgendo analisi anche tramite tecniche non lineari che utilizzano termini di regolarizzazione, algoritmi \textit{lazy} tipo \textit{kNN} e \textit{eager learners} tipo \textit{decision trees}. Inoltre, abbiamo studiato la dipendenza di una colonna rispetto a due colonne indipendenti, utilizzando le stesse tecniche di prima. 
 
Cpme nella sezione precedente, il \textit{dataset} è stato diviso in due parti, dove il  $70\%$ delle righe (scelte randomicamente) sono state usate come set di \textit{training} e l'altro $30\%$ di \textit{test}. 
\subsection{Una variabile indipendente}
12345678


\subsection{Due variabili indipendenti}

Nel caso di due variabili indipendenti abbiamo utilizzato come variabile indipendente la colonna \textit{WeightedRating} con la speranza di poter predirre, tramite tecniche di regressione, l'eventuale successo di un gioco con determinate caratteristiche. Abbiamo provato tutte le coppie tra le seguenti colonne: \textit{Weight}, \textit{Playtime}, \textit{AgeRec}, \textit{NumDesires}, \textit{LanguageEase}, trovando che i risultati migliori si trovavano per la coppia \textit{NumDesires} e \textit{Weight}. 

Abbiamo utilizzato 5 tecniche diverse, eseguendo un fit lineare, un fit lineare con regolarizzazione (utilizzando sia \textit{lasso} che \textit{ridge}), \textit{knn} e \textit{decision trees}. Per fissare i parametri di questi algoritmi abbiamo eseguito le regressioni sul \textit{dataset} di \textit{training} per un valore del parametro, e calcolato il $R^2$ dei risultati sul \textit{dataset} di \textit{test}. Poi, si è fatto variare il valore del parametro, eseguendo uno \textit{sweep} per ogni algoritmo. Abbiamo scelto il miglior valore di ciascun parametro in base al punto di "gomito" della curva ottenuta. Queste curve sono riportate in figura \ref{fig:regression_parameter_sweep}.

\begin{figure}[h]
\includegraphics[width=0.9\linewidth]{../figures/classification/regression/multiple/hyperparameter_tuning_WeightedRating_vs_Weight_NumDesires.png}
\centering
\caption{$R^2$ al variare dei parametri dei diversi modelli di regressione, per \textit{WeightedRating} vs  \textit{NumDesires} e \textit{Weight} }
\label{fig:regression_parameter_sweep}
\end{figure}

Da queste curve si sono impostati i valori dei parametri, e abbiamo eseguito il programma di regressione, ottenendo i risultati riportati in figura \ref{fig:regression_WR_R_NumD}

\begin{figure}[h]
\includegraphics[width=0.9\linewidth]{../figures/classification/regression/multiple/comparison_5x2_WeightedRating_vs_Weight_NumDesires.png}
\centering
\caption{Regressione di \textit{WeightedRating} vs \textit{NumDesires} e \textit{Weight}, i punti rossi rappresentano la regressione sui valori di \textit{test} mentre i punti blu rappresentano i valori di \textit{test} del \textit{dataset}}
\label{fig:regression_WR_R_NumD}
\end{figure}

Guadrdando il $R^2$ come metrica, il miglior risultato ottenuto è tramite l'algoritmo di \textit{decision trees} che spiega $44\%$ della varianza. Questo ci suggerisce che questa coppia di variabili indipendenti non basta per spiegare la varianza del \textit{WeightedRating}, ma già possono essere utilizzate come buoni indicatori per l'eventuale valutazione di un gioco. 



\section{Pattern Mining}

Come ultima analisi abbiamo applicato due algoritmi di \textit{pattern mining} al dataset per trovare correlazioni e per trovare correlazioni e identificare strutture ricorrenti che caratterizzano il \textit{dataset}.
\subsection{FP Growth}
12345678
\section{Conclusioni}

In questo progetto abbiamo svolto un’analisi completa del \textit{dataset} proveniente da BoardGameGeek, affrontando in modo sistematico tutte le fasi del processo di preparazione ed esplorazione dei dati. A partire da una prima comprensione delle variabili, abbiamo identificato criticità strutturali e incoerenze semantiche, applicando una pulizia approfondita che ha permesso di rimuovere valori impossibili, gestire correttamente i dati mancanti e uniformare gli attributi secondo il loro dominio.

La fase di analisi univariata e bivariata ci ha permesso di evidenziare le tendenze generali del \textit{dataset}: una forte asimmetria nelle variabili legate alla popolarità e all’engagement, la predominanza di giochi semplici e adatti a pochi giocatori, e pattern chiari nella distribuzione delle categorie di classificazione. L’analisi tramite istogrammi, \textit{scatterplots} e matrici di correlazione ha inoltre confermato l’esistenza di gruppi di variabili sostanzialmente ridondanti, spesso legate allo stesso concetto o derivate da misure analoghe.

Questi risultati hanno guidato la fase successiva di \textit{data preparation and filtering}, in cui abbiamo ridotto la dimensionalità del \textit{dataset} tramite tecniche di aggregazione, tra cui \textit{PCA} per le coppie fortemente correlate e una trasformazione basata sul \textit{Bayesian shrinkage} per sintetizzare il comportamento dei punteggi degli utenti, ed un \textit{sampling} randomico finale per ridurre la dimensione del \textit{dataset}. Le trasformazioni applicate hanno permesso di ottenere un \textit{dataset} più compatto, interpretabile e pronto per essere analizzato. 


Infine, abbiamo applicato diverse tecniche di \textit{clustering}, tra cui \textit{density-based}, \textit{k-means} e \textit{hierarchical}. Pur individuando alcuni \textit{clusters} con tutti e tre i metodi, la clusterizzazione non ha rivelato informazioni realmente nuove, suggerendo che, per come sono state applicate, queste tecniche non risultano particolarmente efficaci nello studio di questo \textit{dataset}. 

Tuttavia, la mancanza di \textit{clusters} ben separati e convincenti rappresenta essa stessa un risultato: indica infatti che i giochi da tavolo coprono uno spettro sostanzialmente continuo di caratteristiche, e che per ogni tipologia di utente esistono molteplici giochi potenzialmente adatti, senza che emergano gruppi nettamente distinti.


Nel complesso, il lavoro svolto ha portato alla costruzione di un \textit{dataset} più coerente e informativo rispetto all’originale, facilitando le analisi successive e rivelando diverse dinamiche interne al mondo dei giochi da tavolo. Questa base potrà essere ulteriormente sfruttata per future analisi tramite regressioni, classificazioni, e altri studi più approfonditi.

\end{document}