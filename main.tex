\documentclass[10pt,twocolumn]{article}


\usepackage[utf8]{inputenc}
\usepackage{abstract}
\usepackage{geometry}
\usepackage{blindtext}
\usepackage{titlesec}
\usepackage{graphicx}
\usepackage[italian]{babel}
\usepackage[colorlinks=true, linkcolor=black]{hyperref}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{caption}

\graphicspath{ {./figures/} }

\geometry{a4paper, top=2.5cm, bottom=2.5cm, left=2cm, right=2cm}
\setlength{\absleftindent}{3cm}
\setlength{\absrightindent}{3cm}

\title{A Data Mining Study of the BoardGameGeek Dataset}
\author{Leonardo Amabile, Michelangelo Leoni, Jacopo Omodei}
\date{\today}


\begin{document}

\twocolumn[
\maketitle % need full-width title
\begin{onecolabstract}

In questo progetto abbiamo pulito, analizzato e trasformato il \textit{dataset} di BoardGameGeek, correggendo valori errati, riducendo la dimensionalità tramite tecniche di aggregazione e ottenendo un insieme di dati più coerente e interpretabile. Abbiamo studiato distribuzioni, correlazioni e categorie, e applicato diverse tecniche di \textit{clustering}, che non hanno evidenziato gruppi nettamente distinti ma suggeriscono uno spettro continuo di caratteristiche nei giochi da tavolo.

Sul \textit{dataset} finale abbiamo quindi applicato tecniche di \textit{classificazione}, utilizzando modelli \textit{KNN}, \textit{Naive Bayes} e \textit{Decision Trees}, e tecniche di \textit{regressione} sia con una che con due variabili indipendenti, confrontando modelli lineari, regolarizzati e non lineari. Infine, abbiamo esplorato relazioni frequenti tra attributi tramite tecniche di \textit{pattern mining}, utilizzando l’algoritmo \textit{FP-Growth}. Nel complesso, il lavoro fornisce una visione articolata e completa delle dinamiche interne al \textit{dataset}.


\end{onecolabstract}
]

\tableofcontents

\section{Introduzione}
\label{sec:intro}

Il seguente progetto ha come obiettivo l'applicazione delle principali tecniche di analisi affrontate durante il corso \textit{Data Mining: Fundamentals}., utillizando un dataset (\textit{Board Game Geek (BGG)}) riguardante oltre 20{,}000  giochi da tavolo. Il dataset contiene moltissime feature per ogni gioco. 
Nella seguente sezione andremo ad introdurre le variabili che si studieranno durante lo svolgimento del progetto.

\subsection{Semantica dei dati}
\label{sec:semantica}

Ogni riga del \textit{dataset} corrisponde a un gioco da tavolo, identificato univocamente dal suo codice identificativo (\textit{BGGId, int}) e dal suo nome (\textit{Name, str}). 
Il campo \textit{Description} (\textit{str}) contiene una breve descrizione del gioco, fornita dalla comunità online di riferimento. 
L’attributo \textit{YearPublished} (\textit{int}) indica l’anno di pubblicazione del gioco, che per certi giochi antichi viene stimato.

\smallskip
Le complessità del gioco è descritta da due variabili: \textit{GameWeight} e \textit{ComWeight} (\textit{float, intervallo 1--5}), che rappresentano rispettivamente la complessità stimata e quella votata dalla comunità. 
Il numero di voti che hanno contribuito alla valutazione della complessità è fornito da \textit{NumWeightVotes} (\textit{int}). 
Altri attributi legati alla fruibilità includono il numero minimo e massimo di giocatori (\textit{MinPlayers, MaxPlayers, int}), l’età minima consigliata dalla comunità (\textit{ComAgeRec, float}) e il livello di competenza linguistica richiesta (\textit{LanguageEase, float}). 

\smallskip
Le variabili \textit{BestPlayers} (\textit{int}) e \textit{GoodPlayers} (\textit{lista di interi}) sintetizzano le preferenze espresse dalla comunità riguardo ai numeri consigliati di giocatori (\textit{GoodPlayers}) o il numero ideale  (\textit{BestPlayers}) di giocatori per ciascun gioco. 
Altre variabili descrivono la popolarità e la diffusione del gioco all’interno della piattaforma, come \textit{NumOwned}, \textit{NumWant} e \textit{NumWish} (\textit{int}), che indicano rispettivamente quanti utenti possiedono, desiderano o hanno aggiunto il gioco alla propria lista dei desideri.

\smallskip
Sono inoltre presenti variabili relative ai tempi di gioco: \textit{MfgPlayTime} (\textit{int}) rappresenta la durata media riportata dal produttore, mentre \textit{ComMinPlaytime} e \textit{ComMaxPlaytime} (\textit{int}) indicano le stime fornite dalla comunità. 
L’età consigliata dal produttore è fornita da \textit{MfgAgeRec} (\textit{int}). 

\smallskip
Ulteriori informazioni quantitative riguardano l’attività della community: \textit{NumUserRatings} e \textit{NumComments} (\textit{int}) riportano rispettivamente il numero di valutazioni e commenti ricevuti, mentre \textit{NumAlternates}, \textit{NumExpansions} e \textit{NumImplementations} (\textit{int}) indicano il numero di versioni alternative, espansioni e implementazioni collegate al gioco. 
Le variabili booleane \textit{IsReimplementation} e \textit{Kickstarted} (\textit{bool}) segnalano se il gioco rappresenta una reimplementazione di un altro titolo e se è stato finanziato tramite una campagna di \textit{crowdfunding}. 
La variabile \textit{Family} (\textit{str}) indica invece la famiglia ludica di appartenenza, quando disponibile. Un \textit{ImagePath (str)} viene fornito per poter accedere alla foto del gioco.

\smallskip
I giochi inoltre vengono divisi in otto categorie:  (\textit{Thematic, Strategy, War, Family, CGS, Abstract, Party, Childrens}) e vengono anche classificati rispetto a tutti gli altri giochi in base alla categoria (\textit{Rank:strategygames}, \textit{Rank:abstracts}, \textit{Rank:familygames}, \textit{Rank:thematic}, \textit{Rank:cgs}, \textit{Rank:wargames}, \textit{Rank:partygames} e \textit{Rank:childrensgames}). 

\smallskip
Infine, la variabile \textit{Rating} (\textit{Low, Medium, High}) rappresenta una classificazione generale del punteggio complessivo assegnato al gioco dalla comunity, distinguendo tra valutazioni basse, medie e alte.


\section{Preparazione e comprensione dei dati}

Date tutte queste variabili, il primo passo per iniziare a individuare relazioni interessanti nei dati consiste nel pulire il \textit{dataset}, con l’obiettivo di renderlo coerente e di facilitare le operazioni successive. 
Si è verificato che ogni colonna contenesse valori di un solo tipo, che la gestione degli zeri fosse corretta e che eventuali valori errati venissero eliminati. 
Infine, sono state combinate alcune colonne e rimosse quelle non utili ai fini dello studio del presente \textit{dataset}.

\subsection{Pulizia dei dati}
\label{sec:pulizia}

Come prima operazione, sono state eliminate le colonne \textit{ImagePath}, \textit{BGGId} e \textit{NumComments}, poiché non era di nostro interesse analizzare l’immagine del gioco, e il codice identificativo serviva unicamente a distinguere i giochi in modo univoco. 
È stato osservato che in alcuni casi rari (circa 420 su 22{,}000) diversi giochi da tavolo presentavano lo stesso nome; in tali casi, l’identificativo numerico sarebbe stato necessario per distinguerli. 
Tuttavia, poiché non si intende svolgere un’analisi sui singoli giochi, la presenza di questi duplicati non influisce sulla natura statistica dello studio, anche considerando che rappresentano meno del 2\% del \textit{dataset} complessivo.
La colonna \textit{NumComments}, contenente esclusivamente zeri, e quidni è stata rimossa.

\smallskip

Successivamente, si è intervenuti sulle colonne numeriche, decidendo di utilizzare \textit{NaN} come valore identificativo per i dati mancanti. 
Per le colonne in cui lo zero non è un valore ammesso dal dominio della variabile, tutti gli zeri e gli altri valori errati sono stati convertiti in \textit{NaN}. 
Più precisamente, le variabili \textit{GameWeight} e \textit{ComWeight} sono definite nell’intervallo $[1,5]$; pertanto, qualsiasi valore esterno a tale dominio è stato sostituito con \textit{NaN}. 
Le variabili \textit{ComAgeRec}, \textit{LanguageEase}, \textit{MfgPlaytime} e \textit{MfgAgeRec} possono assumere solo valori maggiori di zero, perciò gli zeri presenti sono stati sostituiti con \textit{NaN}.

\smallskip

Per le colonne \textit{MinPlayers}, \textit{MaxPlayers}, \textit{ComMinPlaytime} e \textit{ComMaxPlaytime}, è stato effettuato un controllo per verificare che il valore minimo fosse inferiore a quello massimo. In caso contrario, i due valori sono stati scambiati, e anche in questo caso gli zeri sono stati sostituiti con \textit{NaN}. 
Si è inoltre verificato che tutti i valori della lista \textit{GoodPlayers} fossero compresi nell’intervallo definito da \textit{MinPlayers} e \textit{MaxPlayers}, e che \textit{BestPlayers} fosse contenuto all’interno della lista \textit{GoodPlayers}. 
Ogni violazione di queste condizioni è stata sostituita con \textit{NaN}.

\smallskip

Le 16 colonne relative alle categorie e classificazioni dei giochi sono state condensate in una singola colonna vettoriale di lunghezza 8. 
In sintesi, a ciascun gioco è stato assegnato un vettore che rappresenta la sua classificazione in ognuna delle otto categorie. 
Se un gioco risultava classificato in posizione $21926$ (pari alla lunghezza del dataset), esso è stato considerato come non classificato e l’elemento corrispondente è stato posto a zero. Infatti, abbiamo verificato che ciò avviene solo quando un gioco non appartiene a quella categoria. 
Per le categorie di appartenenza, invece, il valore del \textit{ranking} è stato inserito come elemento del vettore. 
Questa strategia consente di considerare anche i giochi che appartengono a nessuna o a più categorie, senza perdita di generalità.

\smallskip

La colonna \textit{Description} è stata convertita in una lista di stringhe, separando parola per parola ed eliminando i duplicati. 
Infine, la colonna \textit{Rating} è stata trasformata in una colonna contenente solo i valori $\{-1, 0, 1\}$, mappando direttamente \textit{Low $\rightarrow$ -1}, \textit{Medium $\rightarrow$ 0} e \textit{High $\rightarrow$ 1}.


\subsection{Studio delle singole variabili}
\label{sec:studio_singole}
\subsubsection{Distribuzione delle colonne numeriche}
\label{sec:histos}

Come prima analisi, abbiamo studiato ciascun attributo numerico singolarmente, creando un istogramma per visualizzarne la distribuzione. 
Utilizzando il criterio di \textit{Sturges} per determinare il \textit{binning}, ci siamo accorti che, per la maggior parte delle colonne numeriche, la presenza di pochi \textit{outlier} dominava il grafico, rendendo gli istogrammi poco leggibili e ostacolando l’analisi dei dati. 
Per migliorare la qualità della visualizzazione, abbiamo deciso di calcolare i percentili ($5, 25, 50, 75, 95\%$) e di mantenere solo i dati compresi tra i percentili $5\%$ e $95\%$. 
Questo metodo si basa sulla tecnica dello \textit{scarto interquantile}, che rappresenta una statistica robusta rispetto agli \textit{outlier} per distribuzioni sufficientemente popolate, come nel nostro caso. 

Un esempio di distribuzione prima e dopo questa pulizia è mostrato in figura \ref{fig:histo_YearPublished}, dove nella colonna \textit{YearPublished} sono stati rimossi tutti i giochi pubblicati prima del $1978$ e dopo il $2020$, considerati \textit{outlier} secondo questa metrica. 
Solo il $7.88\%$ dei dati è stato rimosso, ma la leggibilità della distribuzione è migliorata in modo significativo. 

\begin{figure}[ht!]
\includegraphics[width=0.9\linewidth]{/histograms/all_data/analisi_singola_yearpublished.png}
\centering
\caption{Distribuzione della colonna \textit{YearPublished} prima e dopo la rimozione degli \textit{outlier} (considerando solo i valori compresi tra i percentili $5\%$ e $95\%$). Il \textit{binning} è stato scelto utilizzando il criterio di \textit{Sturges}.}
\label{fig:histo_YearPublished}
\end{figure}

Abbiamo svolto un’analisi analoga per tutte le colonne numeriche, creando un \textit{box plot} sovrapposto a un istogramma per i dati originali e ripetendo la procedura per i dati filtrati secondo il criterio descritto in precedenza (mantenendo solo i valori tra i percentili $5\%$ e $95\%$). 
La figura \ref{fig:histo_box_not_cleaned} riporta tutti gli istogrammi generati utilizzando i dati grezzi, mentre la figura \ref{fig:histo_box_cleaned} mostra gli stessi istogrammi dopo la pulizia applicata con il metodo discusso.

\begin{figure}[ht!]
\includegraphics[width=0.9\linewidth]{/histograms/all_data/Histogram_Matrix_all_data_unfiltered.png}
\centering
\caption{Distribuzioni delle variabili numeriche senza alcuna filtratura sul \textit{dataset} pulito. 
La visualizzazione è ottenuta tramite istogrammi sovrapposti a \textit{box plot}. 
I percentili corrispondono al $5, 25, 50, 75, 95\%$ dei dati originali. 
Il \textit{binning} è stato determinato utilizzando il criterio di \textit{Sturges}.}
\label{fig:histo_box_not_cleaned}
\end{figure}

\begin{figure}[ht!]
\includegraphics[width=0.9\linewidth]{/histograms/all_data/Histogram_Matrix_all_data_filtered.png}
\centering
\caption{Distribuzioni delle variabili singole dopo la rimozione degli \textit{outlier} (considerando solo i valori compresi tra i percentili $5\%$ e $95\%$). La visualizzazione è ottenuta tramite istogrammi sovrapposti a \textit{box plot}. I percentili corrispondono al $5, 25, 50, 75, 95\%$ dei dati filtrati. Il \textit{binning} è stato determinato utilizzando il criterio di \textit{Sturges}.}
\label{fig:histo_box_cleaned}
\end{figure}

Si osserva che la maggior parte delle distribuzioni presenta una forte asimmetria verso valori bassi, con un picco concentrato in prossimità del minimo. 
Più precisamente, i giochi più semplici (sia in termini di complessità del gioco sia di linguaggio) e con una durata più breve risultano più frequenti. 
Inoltre, i giochi che prevedono un numero ridotto di partecipanti (tipicamente da 2 a 4 giocatori) sono i più comuni, pur rimanendo superiori a uno, quindi non si tratta di giochi solitari. 
Questo suggerisce che, nel mondo dei giochi da tavolo, vengono prodotti più frequentemente titoli semplici e accessibili, che richiedono un numero relativamente basso di giocatori per essere apprezzati. 
Si nota inoltre che la maggior parte dei giochi è destinata a un pubblico di ragazzi tra gli 8 e i 12 anni.

\smallskip
Negli ultimi anni si osserva una crescita significativa del numero di giochi presenti nel \textit{dataset}, indicando che l’industria continua a espandersi. 
Nel 2020, tuttavia, si registra un calo rispetto all’anno precedente, probabilmente dovuto all’impatto della quarantena.

\smallskip
Per quanto riguarda le colonne \textit{booleane}, si nota che la maggior parte dei giochi non presenta implementazioni, versioni alternative o espansioni, e non è stata finanziata tramite campagne di \textit{crowdfunding}.  
Inoltre, la maggior parte dei giochi risulta posseduta da meno di mille persone (secondo i dati riportati nel \textit{dataset}). 
Le variabili legate all’\textit{engagement} degli utenti sul sito mostrano distribuzioni fortemente asimmetriche verso zero: \textit{NumWant}, \textit{NumWish} e \textit{NumWeightVotes} seguono tutte questo andamento, con la maggior parte dei valori inferiori al centinaio. 

Bisogna tenere conto del fatto che noi possiamo solo trarre conclusioni sui dati che abbiamo, e che il \textit{dataset} non è necessariamente descrittivo della realtà in maniera completa. Tuttavia, con questi dati si riescono comunque a trovare degli andamenti interessanti nelle singole colonne numeriche. 

\subsubsection{Distribuzione delle categorie}
\label{sec:categorie}

Abbiamo effettuato anche uno studio completo delle categorie dei giochi. 
Come prima analisi, abbiamo verificato quanti giochi appartengono a più di una categoria e quante categorie sono coinvolte in media. 
Questa informazione è riportata in figura \ref{fig:num_cats}, dove si osserva che la maggior parte dei giochi non è categorizzata oppure appartiene solo a una o due categorie.

\begin{figure}[ht!]
\includegraphics[width=0.9\linewidth]{/category_figures/distribuzione_numero_categorie_per_gioco.png}
\centering
\caption{Numero di categorie a cui appartiene ogni gioco, in scala logaritmica. Ogni gioco è stato contato una sola volta, indipendentemente dal numero di categorie al quale apparteneva.}
\label{fig:num_cats}
\end{figure}

Abbiamo inoltre analizzato la distribuzione delle singole categorie, contando quante volte ciascuna compare nel \textit{dataset}. 
I risultati sono mostrati in figura \ref{fig:distr_cats}. 
Si nota immediatamente che i giochi di guerra sono i più comuni, seguiti da quelli di strategia e da quelli di famiglia.

\begin{figure}[ht!]
\includegraphics[width=0.9\linewidth]{/category_figures/distribuzione_delle_categorie.png}
\centering
\caption{Distribuzione delle categorie di classificazione dei giochi.}
\label{fig:distr_cats}
\end{figure}

Successivamente, abbiamo studiato la distribuzione delle categorie prese a coppie. 
Ci siamo chiesti se esistesse una correlazione tra le categorie per i giochi che appartengono contemporaneamente a due di esse. 
Abbiamo quindi creato una \textit{heatmap} che visualizza il numero di co-occorrenze per ogni possibile coppia di categorie, mostrata in figura \ref{fig:heatmap_cats}. 
In questa figura, la diagonale rappresenta il numero totale di giochi appartenenti a ciascuna categoria singola, mentre gli elementi fuoir diagonale indicano il numero di giochi che condividono entrambe le categorie. 
La scala dei colori è stata impostata su base logaritmica, poiché i dati coprono diversi ordini di grandezza.

\begin{figure}[ht!]
\includegraphics[width=0.9\linewidth]{/category_figures/category_couples_heatmap.png}
\centering
\caption{Occorrenze delle varie coppie di categorie per i giochi appartenenti a due categorie. 
La diagonale rappresenta il numero di occorrenze della singola categoria. 
La scala dei colori è logaritmica.}
\label{fig:heatmap_cats}
\end{figure}

La figura \ref{fig:heatmap_cats} mostra solo il numero assoluto di co-occorrenze per ciascuna coppia; tuttavia, le categorie più popolose singolarmente (come \textit{war}, \textit{strategy} e \textit{family}) tendono naturalmente ad avere anche più co-occorrenze. 
Per tenere conto di questo effetto, abbiamo introdotto un fattore di normalizzazione definito come

\begin{equation}
	\centering
	M_{i,j}^\prime = \frac{M_{i,j}}{\sqrt{M_{i,i}\cdot M_{j,j}}}
	\label{eq:norm_cat}
\end{equation}

dove ogni elemento della matrice è normalizzato in base al numero di occorrenze delle categorie singole. 
Per costruzione, l’equazione (\ref{eq:norm_cat}) impone che la diagonale valga 1, mentre tutti gli elementi fuori diagonale risultino compresi normalizzati nell’intervallo $[0,1]$. 
La \textit{heatmap} normalizzata è mostrata in figura \ref{fig:heatmap_cats_norm}, dove la diagonale è stata eliminata (posta uguale a zero) per mettere in risalto i valori non banali.

\begin{figure}[ht!]
\includegraphics[width=0.9\linewidth]{/category_figures/category_couples_heatmap_norm.png}
\centering
\caption{Co-occorrenze normalizzate delle varie coppie di categorie per i giochi appartenenti a due categorie, secondo l’equazione (\ref{eq:norm_cat}). 
La diagonale è stata posta uguale a zero per chiarezza. 
I valori fuori diagonale perdono significatività dopo la normalizzazione e sono stati quindi omessi.}
\label{fig:heatmap_cats_norm}
\end{figure}

Dalla figura \ref{fig:heatmap_cats_norm} si osserva che la coppia \textit{strategy–family} rimane la più frequente, ma ora è evidente che ciò non è dovuto unicamente all’elevata numerosità delle due categorie. 
Si nota inoltre che, mentre nel conteggio grezzo le coppie \textit{family–party} e \textit{thematic–war} presentavano quasi lo stesso numero di co-occorrenze ($156$ e $157$ rispettivamente), la coppia \textit{family–party} risulta più correlata una volta tenuto conto del numero molto elevato di giochi di guerra presenti nel \textit{dataset}. 

\smallskip
Non abbiamo analizzato le co-occorrenze tra tre o più categorie poiché un numero trascurabile di giochi appartiene contemporaneamente a tre categorie, come già mostrato in figura \ref{fig:num_cats}. 

\smallskip
Nel complesso, le figure \ref{fig:num_cats}, \ref{fig:distr_cats}, \ref{fig:heatmap_cats} e \ref{fig:heatmap_cats_norm} forniscono un quadro completo della distribuzione e delle correlazioni tra le categorie dei giochi da tavolo.

\subsubsection{Distribuzione delle descrizioni}
\label{sec:distro_descriz}
Infine, abbiamo studiato la distribuzione delle descrizioni dei giochi. Dopo aver convertito ogni colonna in una lista di stringhe, e assicurandoci che ogni parola comparisse una sola volta per lista, abbiamo creato un grafico a barre per visualizzare le occorrenze delle parole singole. Questo grafico si vede in figura \ref{fig:top_words}.

\begin{figure}[ht!]
\includegraphics[width=0.9\linewidth]{/top_words/occorrenza_delle_parole_più_usate_nelle_descrizioni.png}
\centering
\caption{Grafico a barre delle occorrenze delle singole parole nella colonna \textit{Descriptions} del dataset.
Ci siamo assicurarti di eliminare le occorrenze doppie delle parole.}
\label{fig:top_words}
\end{figure}

Non ci sorprende che le parole più comuni nelle descrizioni sono "game", "player", "win", "turn", e altre parole simili che si riferiscono ad un gioco in generale.

\subsection{Studio delle variabili a coppia}
\label{sec:coppie}
Avendo studiato gli attributi dei giochi singolarmente, il prossimo passo nella nostra comprensione del \textit{dataset} è di analizzare le colonne numeriche due a due, generando vari \textit{scatterplots} e matrici di correlazione per identificare pattern che ci potrebbero essere sfuggiti nell'analisi precedente. 

\subsubsection{Visualizzazione delle coppie di variabili}
\label{sec:scatters}

Come primo passo, abbiamo generato un insieme di \textit{scatterplot} per alcune colonne numeriche. 
Abbiamo escluso le variabili \textit{booleane}, come \textit{IsReimplementation}, \textit{Kickstarted} e \textit{Rating}, e quelle con varianza molto bassa, come \textit{MinPlayers}, \textit{MaxPlayers}, \textit{BestPlayers}, \textit{GoodPlayers}, \textit{NumImplementations}, \textit{NumExpansions}, \textit{NumAlternates} e \textit{NumWeightVotes}. 
Queste colonne, assumendo pochi valori discreti, non sono adatte a essere rappresentate tramite \textit{scatterplot}; pertanto, per ridurre la dimensione dell’insieme di grafici, non sono state confrontate con le altre. 
La figura \ref{fig:scatter_unfiltered} mostra tutte le coppie tra le variabili numeriche rimanenti, considerando ciascuna combinazione una sola volta.

\begin{figure}[ht!]
\includegraphics[width=0.9\linewidth]{/scatterplots/all_data/Scatterplots_all_data_unfiltered}
\centering
\caption{\textit{Scatterplot} delle variabili numeriche di interesse. 
I dati non sono stati filtrati in alcun modo e ogni coppia compare una sola volta.}
\label{fig:scatter_unfiltered}
\end{figure}

Utilizzando lo stesso criterio di pulizia dei dati discusso nella sezione \ref{sec:histos} (basato sulla rimozione dei valori al di fuori dei percentili $5\%$ e $95\%$), abbiamo generato un secondo insieme di \textit{scatterplot} utilizzando i dati depurati dagli \textit{outlier}. 
Questo consente di visualizzare meglio le zone più dense e centrali delle distribuzioni, come mostrato in figura \ref{fig:scatter_filtered}.

\begin{figure}[ht!]
\includegraphics[width=0.9\linewidth]{/scatterplots/all_data/Scatterplots_all_data_filtered}
\centering
\caption{\textit{Scatterplot} delle variabili numeriche di interesse. 
I dati sono stati filtrati rimuovendo i valori al di fuori dei percentili più esterni ($5\%$ e $95\%$). 
Ogni coppia compare una sola volta.}
\label{fig:scatter_filtered}
\end{figure}

La maggior parte delle coppie di variabili risulta distribuita in modo apparentemente scorrelato, con punti distribuiti uniformemente sul piano. 
Alcune coppie, tuttavia, mostrano una chiara correlazione positiva, evidenziata da un andamento lineare nei rispettivi \textit{scatterplot}. 
Queste correlazioni verranno discusse più nel dettaglio nella prossima sezione (\ref{sec:correlazioni}), ma già da ora si può osservare una correlazione quasi 1:1 tra \textit{ComWeight} e \textit{GameWeight}.

\subsubsection{Correlazione tra coppie di variabili}
\label{sec:correlazioni}

Per approfondire quanto osservato nella sezione precedente, abbiamo creato una \textit{heatmap} basata sull’indice di correlazione di Pearson tra le variabili considerate. 
Il criterio di selezione delle colonne numeriche è lo stesso adottato nella sezione \ref{sec:scatters}. 
La \textit{heatmap} di correlazione è mostrata in figura \ref{fig:heatmap_corr}.

\begin{figure}[ht!]
\centering
\includegraphics[width=0.9\linewidth]{/heatmaps/correlation_heatmap_unfiltered.png}
\caption{Matrice di correlazione tra le colonne numeriche analizzate. 
I dati non sono stati filtrati in alcun modo.}
\label{fig:heatmap_corr}
\end{figure}

Come di consueto, abbiamo applicato il nostro criterio di filtraggio basato sulla tecnica descritta nelle sezioni precedenti, e il risultato della pulizia è riportato in figura \ref{fig:heatmap_corr_filt}.

\begin{figure}[ht!]
\includegraphics[width=0.9\linewidth]{/heatmaps/correlation_heatmap_filtered.png}
\centering
\caption{Matrice di correlazione tra le colonne numeriche analizzate. 
I dati sono stati filtrati rimuovendo i valori al di fuori dei percentili più esterni ($5\%$ e $95\%$).}
\label{fig:heatmap_corr_filt}
\end{figure}

Come anticipato, la correlazione tra \textit{ComWeight} e \textit{GameWeight} risulta massima nell’indice di Pearson. 
Questo risultato non sorprende, poiché entrambe le variabili rappresentano due stime della stessa misura e sono quindi strettamente correlate. 
Di conseguenza, qualsiasi variabile correlata a una di esse risulterà correlata anche all’altra nello stesso modo.

\smallskip 
Un comportamento analogo si osserva tra \textit{ComAgeRec} e \textit{MfgAgeRec}, che rappresentano rispettivamente l’età consigliata dalla comunità e quella proposta dal produttore; anche in questo caso la correlazione è praticamente 1:1. 

Le variabili \textit{NumUserRatings} e \textit{NumOwned} sono fortemente correlate, poiché un utente può lasciare una valutazione solo per un gioco che possiede. 
Analogamente, \textit{NumWish} e \textit{NumWant} risultano strettamente correlate, in quanto entrambe misurano l’interesse dell’utenza verso un gioco. 

Infine, \textit{ComMaxPlaytime} e \textit{MfgPlaytime} sono anch’esse fortemente correlate, suggerendo che i produttori tendono a utilizzare il tempo massimo di gioco stimato dalla comunità come riferimento per la durata indicata ufficialmente.

\smallskip
In tutti questi casi, le correlazioni derivano dal fatto che le variabili rappresentano misure equivalenti o strettamente connesse dello stesso concetto. 
Pertanto, ai fini dell’analisi, tali variabili possono essere considerate ridondanti. 
Per ridurre la dimensionalità e mettere meglio in evidenza le altre relazioni, abbiamo rimosso le variabili \textit{ComWeight}, \textit{ComAgeRec}, \textit{NumUserRatings}, \textit{MfgPlaytime} e \textit{NumWish}. 
La nuova matrice di correlazione è riportata in figura \ref{fig:heatmap_corr_filt_dim}.

\begin{figure}[ht!]
\includegraphics[width=0.9\linewidth]{/heatmaps/correlation_heatmap_filtered_diminished.png}
\centering
\caption{Matrice di correlazione tra le colonne numeriche analizzate, dopo la rimozione di una variabile per ciascuna coppia correlata 1:1. 
I dati sono stati filtrati rimuovendo i valori al di fuori dei percentili più esterni ($5\%$ e $95\%$).}
\label{fig:heatmap_corr_filt_dim}
\end{figure}

Dopo la pulizia del \textit{dataset}, emergono nuove correlazioni precedentemente nascoste dagli \textit{outlier}. 
Ad esempio, si osserva una relazione positiva tra la complessità del gioco, il tempo di gioco e l’età consigliata. 
Questo risultato è intuitivo: i giochi più complessi tendono a richiedere più tempo e sono destinati a un pubblico più maturo. 
Di conseguenza, si evidenzia una correlazione diretta tra età e durata del gioco.

Anche il tempo minimo e quello massimo di gioco risultano fortemente correlati: per definizione il tempo massimo deve essere maggiore del minimo, ma l’intensità della correlazione suggerisce che i giochi più lunghi presentano in generale tempi elevati in entrambe le misure.

Infine, il numero di utenti che desiderano un gioco (\textit{NumWant}) è positivamente correlato con il numero di utenti che lo possiedono (\textit{NumOwned}). 

\smallskip
Queste ultime correlazioni, pur non essendo perfettamente 1:1, forniscono comunque informazioni utili sulla struttura del \textit{dataset}. 
Esse mostrano, ad esempio, come alcuni valori riportati dai produttori riflettano direttamente le stime fornite dalla comunità - come nel caso del tempo di gioco indicato, fortemente correlato con il tempo massimo riportato dagli utenti - e come diversi indicatori di popolarità descrivano aspetti complementari dello stesso fenomeno.
\subsection{Preparazione finale dei dati}
\label{sec:prep}

Ora che abbiamo compreso il comportamento generale dei dati, vogliamo intervenire sul \textit{dataset} per renderlo più leggero, coerente e analizzabile. 
Sono state quindi applicate tecniche di aggregazione per ridurre il numero di colonne, di \textit{sampling} per diminuire il numero di righe e trasformazioni di variabili per migliorarne la compatibilità e l’interpretabilità.

\smallskip

L’intero \textit{dataset} è stato filtrato rimuovendo, da ogni colonna numerica, i valori considerati \textit{outlier}, utilizzando il consueto metodo di selezione: sono stati eliminati tutti i valori al di fuori dei percentili $5\%$ e $95\%$.

\subsubsection{Aggregazione dei dati}
\label{sec:aggr}

Come primo passo nella fase di preparazione finale del \textit{dataset}, abbiamo utilizzato i risultati ottenuti nella sezione \ref{sec:correlazioni} per identificare quali attributi fossero ridondanti in base alla loro correlazione reciproca. 
Come già discusso, sono state individuate quattro coppie di variabili altamente correlate: \textit{ComAgeRec} e \textit{MfgAgeRec}, \textit{NumWish} e \textit{NumWant}, \textit{ComWeight} e \textit{GameWeight}, e infine \textit{MfgPlaytime} e \textit{ComMaxPlaytime}. 
Data l’elevata correlazione tra le variabili di ciascuna coppia, abbiamo applicato una \textit{Principal Component Analysis (PCA)} per sostituire ogni coppia con una singola colonna che ne descrivesse la tendenza principale. 
Le nuove colonne sono state denominate \textit{AgeRec}, \textit{NumDesires}, \textit{Weight} e \textit{Playtime}, rispettivamente. 
In questo modo, otto colonne sono state aggregate in quattro.\footnote{Poiché la correlazione tra le coppie di variabili è prossima a 1, si potrebbe anche eliminare una delle due colonne e mantenere l’altra. Tuttavia, l’approccio con PCA evita una scelta arbitraria e rende l’analisi più generale.}
Tutte le nuove colonne sono state normalizzate tramite \textit{min–max scaling}, riportando i valori nell’intervallo $[0,1]$.

\smallskip
Un’altra coppia di variabili fortemente correlate è costituita da \textit{NumUserRatings} e \textit{NumOwned}. 
Invece di applicare nuovamente la \textit{PCA}, abbiamo scelto di aggregarle tramite una trasformazione che combinasse l’informazione contenuta in entrambe. 
Per ottenere una stima del \textit{rating} pesata in base al numero di voti, abbiamo impiegato la tecnica del \textit{Bayesian shrinkage}, comunemente utilizzata da siti che classificano film, giochi o prodotti in base alle valutazioni degli utenti. 
La formula utilizzata è la seguente:

\begin{equation}
	\text{score} = \frac{n \cdot s + m \cdot \sigma}{n + m}
	\label{eq:weighted_score}
\end{equation}

dove $n$ rappresenta il numero di voti, $s$ il punteggio del gioco ($\{-1, 0, 1\}$), $m$ il numero medio di voti e $\sigma$ la media globale del punteggio su tutto il \textit{dataset}. 
Abbiamo quindi sostituito le colonne \textit{NumUserRatings} e \textit{NumOwned} con una singola colonna, denominata \textit{WeightedRatings}, riducendo la dimensionalità del \textit{dataset} e, allo stesso tempo, arricchendo l’informazione contenuta nella variabile \textit{Rating}. 
Anche questa colonna è stata infine normalizzata nell’intervallo $[0,1]$ tramite \textit{min–max scaling}.

\smallskip

Infine, la colonna \textit{LanguageEase} è stata trasformata applicando una funzione logaritmica, per rendere la distribuzione più simmetrica, e successivamente normalizzata nell’intervallo $[0,1]$ con \textit{min–max scaling}.  
Le distribuzioni delle colonne trasformate e aggregate sono mostrate in figura \ref{fig:histoboxmatrix_transformed}.

\begin{figure}[ht!]
\includegraphics[width=0.9\linewidth]{/columns_transformed/all_data/histo_box_matrix_transformed_all_data.png}
\centering
\caption{Distribuzioni delle variabili numeriche trasformate e aggregate. 
La visualizzazione è ottenuta tramite istogrammi sovrapposti a \textit{box plot}. 
I percentili corrispondono al $5, 25, 50, 75, 95\%$ dei dati originali. 
Il \textit{binning} è stato determinato utilizzando il criterio di \textit{Sturges}.}
\label{fig:histoboxmatrix_transformed}
\end{figure}

Come si può osservare, le distribuzioni risultano ora più centralizzate e leggibili, permettendo di analizzare con maggiore chiarezza l’andamento delle variabili, pur avendo ridotto la dimensionalità complessiva del \textit{dataset}.

\subsubsection{Sampling}
\label{sec:sampl}

Come prossimo passo, abbiamo deciso di implementare delle tecniche di \textit{sampling} per ridurre la quantità di dati con lo scopo di perdere il numero minimo di informazione. Abbiamo usato un \textit{random sampling}, selezionando randomicamente con rimozione da tutte le righe possibile, con una probabilità uniforme per ogni riga. Abbiamo confrontato la distribuzione di alcune colonne \textit{sampled} randomicamente con $2000$ righe rispetto a no sampling. Si vede in figura \ref{fig:sampling_comparison_agerec} il confronto tra la distribuzione della colonna \textit{AgeRec} prima e dopo del \textit{sampling}.


\begin{figure}[ht!]
\includegraphics[width=0.9\linewidth]{/sampling/all_data/AgeRec_histogram_comparison.png}
\centering
\caption{Distribuzione della colonna \textit{AgeRec} prima e dopo del \textit{sampling} randomico.
Sono stati presi \textit{2000} righe randomiche, con rimozione. 
Il \textit{binning} è stato determinato utilizzando il criterio di \textit{Sturges}.}
\label{fig:sampling_comparison_agerec}
\end{figure}

Come si vede in figura, i percentili dei dati sono rimasti per lo più inalterati, e la forma della distribuzione rimane simile. Questo ci dimostra che un \textit{sampling} randomico può essere un'ottimo metodo per ridurre la quantità di dati pur mantenedo le caratteristiche importanti della distribuzione, almeno per quanto riguarda $2000$ \textit{samples}. 
\section{Clustering}
\label{sec:clustering}

Nel trattamento del \textit{dataset} abbiamo applicato diverse tecniche di \textit{clustering} per cercare relazioni tra coppie di variabili. Sono stati utilizzati vari metodi, tra cui \textit{density-based clustering}, \textit{k-means} (analizzando anche il variare della \textit{SSE} al variare di $k$) e \textit{hierarchical clustering}. 
L’analisi si è concentrata principalmente sulla relazione tra \textit{WeightedRating} e \textit{NumDesires}, e tra \textit{WeightedRating} e \textit{AgeRec}.

\subsection{Density-based}
\label{sec:density}

Come prima analisi abbiamo utilizzato un algoritmo di \textit{density-based clustering}, come mostrato nelle figure \ref{fig:db_numdes_weightedr} e \ref{fig:db_weightedr_agerec}. 

L'algoritmo DBSCAN è governato da due iperparametri fondamentali: il raggio $\varepsilon$ e il numero minimo di punti $N_{min}$. Per la determinazione dei valori ottimali, si è proceduto fissando inizialmente $N_{min}$ e derivando $\varepsilon$ mediante l'analisi del grafico delle k-distanze (k-distance plot).
Nello specifico, è stata calcolata la distanza di ogni punto dal suo $N_{min}$-esimo vicino più prossimo; tali distanze sono state successivamente ordinate in modo crescente, come mostrato nelle Figure \ref{fig:db_numdes_weightedr} e \ref{fig:db_weightedr_agerec}. Il valore di soglia per $\varepsilon$ è stato identificato in corrispondenza del 'gomito' (knee point) della curva, ovvero il punto in cui si osserva un drastico incremento della pendenza. Tale criterio permette di definire una soglia di densità che include nei cluster i punti spazialmente coesi, relegando a rumore (outliers) le osservazioni caratterizzate da distanze inter-punto eccessivamente elevate. 

\begin{figure}[ht!]
\includegraphics[width=0.9\linewidth]{../figures/clustered_scatters/dbscan_numdesires_vs_weightedrating.png}
\centering
\caption{Density-based clustering di weighted rating vs numdesires}
\label{fig:db_numdes_weightedr}
\end{figure}

\begin{figure}[ht!]
\includegraphics[width=0.9\linewidth]{../figures/clustered_scatters/dbscan_weightedrating_vs_agerec.png}
\centering
\caption{Density-based clustering di weighted rating vs agerec}
\label{fig:db_weightedr_agerec}
\end{figure}


In figura \ref{fig:db_numdes_weightedr} si nota un cluster che copre valori medi di \textit{WeightedRating} per quasi tutte le età considerate. Questo suggerisce che esistono giochi valutati in maniera neutra indipendentemente dalla fascia d’età, mentre altri giochi — pensati per categorie di età più specifiche — presentano valutazioni differenti, come mostrato dagli altri \textit{clusters}. Ad esempio è presente un cluster nella sezione inferiore dell'immagine che includerà tutti quei giochi valutati male e poco desiderati, mentre nel cluster in alto a sinistra potrebbero esserci dei giochi poco popolari ma molto ben valutati.

Invece, in figura \ref{fig:db_weightedr_agerec} si osservano 2 cluster importanti nella fascia centrale del grafico, quindi ci sono molti giochi con una valutazione media che vanno bene per tutte le età; però ci sono anche dei piccoli cluster che potrebbero essere delle categorie di giochi ben valutate per specifiche fasce di età. 

\subsection{K-means}
\label{sec:kmeans}

L'analisi è proseguita applicando l'algoritmo \textit{k-means clustering} (Figure \ref{fig:kmeans_numdes_weightedr} e \ref{fig:kmeans_weightedr_agerec}). Per individuare il numero ottimale di cluster $k$, si è studiata la variazione della SSE (Sum of Squared Errors) al variare di $k$. Applicando il criterio del 'gomito' (Elbow Method), è stato selezionato il valore di $k$ corrispondente al punto di maggior cambio di pendenza della curva; oltre tale soglia, infatti, la riduzione dell'errore diventa marginale rispetto all'aumento della complessità del modello.

\begin{figure}[ht!]
\includegraphics[width=0.9\linewidth]{../static_images/numdesires_vs_weightedrating/sse_vs_k_numdesires_vs_weightedrating.png}
\centering
\caption{SSE del K-means clustering weighted rating vs numdesires, al variare di \textit{k}}
\label{fig:sse_numdes_weightedr}
\end{figure}

\begin{figure}[ht!]
\includegraphics[width=0.9\linewidth]{../static_images/weightedrating_vs_agerec/sse_vs_k_weightedrating_vs_agerec.png}
\centering
\caption{SSE del K-means clustering weighted rating vs agerec, al variare di \textit{k}}
\label{fig:sse_weightedr_agerec}
\end{figure}

Come atteso, la \textit{SSE} diminuisce all’aumentare del numero di centroidi, e le figure confermano questo andamento. 
Per evitare \textit{overfitting}, abbiamo scelto $k=4$, corrispondente al punto di “gomito” della curva. In più abbiamo ripetuto l'algoritmo 10 volte per ogni coppia di variaili e posto un massimo di iterazioni pari a 10. In questo modo si ovvia al problema della selezione iniziale dei centroidi e si riduce il numero di operazioni da effettuare. I risultati sono i seguenti:

\begin{figure}[ht!]
\includegraphics[width=0.9\linewidth]{../figures/clustered_scatters/k_means_numdesires_vs_weightedrating.png}
\centering
\caption{K-means clustering weighted rating vs numdesires, 4 \textit{clusters}}
\label{fig:kmeans_numdes_weightedr}
\end{figure}

\begin{figure}[ht!]
\includegraphics[width=0.9\linewidth]{../figures/clustered_scatters/k_means_weightedrating_vs_agerec.png}
\centering
\caption{K-means clustering weighted rating vs agerec, 4 \textit{clusters}}
\label{fig:kmeans_weightedr_agerec}
\end{figure}

In questo caso i \textit{clusters} si separano in base alla fascia d’età (figura \ref{fig:kmeans_weightedr_agerec}) o principalmente in base al punteggio pesato (figura \ref{fig:kmeans_numdes_weightedr}). 

Per interpretare i risultati ottenuti in legenda è presente il valore di SSE calcolato su un k-means con lo stesso valore di k del plot ma su dei dati distribuiti uniformemente sul piano. Se il nostro valore di SSE è confrontabile con quello del dataset random vuol dire che i nostri dati sono distribuiti praticamente in modo uniforme. In entrambi i plot il valore di SSE è inferiore rispetto a quello del dataset random, ma i cluster che mostra non sono fortemente riconoscibili. L'unica cosa che si può notare è che nel grafico in Figura \ref{fig:kmeans_weightedr_agerec} un cluster comprende i giochi peggiori e meno desiderati. È evidente come il K-means non si presti a queste \textit{features}, probabilmente perchè il dataset non ha dei potenziali clusters di forma globulare, ha forti variazioni di densità ed è rumoroso. 


\subsection{Hierarchical clustering}
\label{sec:hierarchical}

Come ultima tecnica, abbiamo applicato l’\textit{hierarchical clustering} alle stesse variabili considerate finora. I risultati sono riportati nelle figure \ref{fig:hie_numdes_weightedr} e \ref{fig:hie_weightedr_agerec}.

\begin{figure}[ht!]
\includegraphics[width=0.9\linewidth]{../figures/clustered_scatters/hierarchical_numdesires_vs_weightedrating.png}
\centering
\caption{Hierarchical clustering weighted rating vs numdesires}
\label{fig:hie_numdes_weightedr}
\end{figure}

\begin{figure}[ht!]
\includegraphics[width=0.9\linewidth]{../figures/clustered_scatters/hierarchical_weightedrating_vs_agerec.png}
\centering
\caption{Hierarchical clustering weighted rating vs agerec}
\label{fig:hie_weightedr_agerec}
\end{figure}

Dall’immagine \ref{fig:hie_numdes_weightedr} possiamo osservare 5 clusters: in rosa compaiono i giochi poco apprezzati e poco desiderati; in verde quelli mediamente valutati ma con scarso interesse da parte degli utenti (la categoria più numerosa); in azzurro i giochi molto desiderati ma con valutazioni nella media (come titoli minori diventati popolari grazie alla notorietà della casa produttrice o varianti meno riuscite) in giallo i giochi ben valutati ma poco desiderati( magari titoli di nicchia molto apprezzati); infine, in violetto, i giochi più popolari e meglio valutati.

Purtroppo per quanto riguarda la figura \ref{fig:hie_weightedr_agerec} non possiamo dire molto, anche variando i metodi di \textit{linkage} e il numero di clusters non sono stati ottenute separazioni significative.

Sono inoltre riportati i rispettivi \textit{dendrogram} in figure \ref{fig:ddg_numdes_weightedr} e \ref{fig:ddg_weightedr_agerec}.

\begin{figure}[ht!]
\includegraphics[width=0.9\linewidth]{../figures/clustered_scatters/dendrogram_numdesires_vs_weightedrating.png}
\centering
\caption{Dendrogram dell’hierarchical clustering weighted rating vs numdesires}
\label{fig:ddg_numdes_weightedr}
\end{figure}

\begin{figure}[ht!]
\includegraphics[width=0.9\linewidth]{../figures/clustered_scatters/dendrogram_weightedrating_vs_agerec.png}
\centering
\caption{Dendrogram dell’hierarchical clustering weighted rating vs agerec}
\label{fig:ddg_weightedr_agerec}
\end{figure}

Osservando i diagrammi ad albero, si nota come la scelta di suddividere le due coppie di categorie in 4-5 cluster risulti appropriata: tracciando una linea orizzontale sull’albero è infatti possibile ottenere una suddivisione significativa dell’intero set di dati. Questa scelta è inoltre corroborata dall'analisi della curva SSE (Elbow Method) effettuata precedentemente, che indicava un gomito proprio in corrispondenza di k=4 o k=5.

\section{Classificazione}
\label{sec:classification}

Come passo successivo abbiamo utilizzato diverse tecniche di classificazione con lo scopo di prevedere il possibile \textit{rating} di un gioco a partire dai suoi attributi. Abbiamo esplorato sia tecniche \textit{lazy}, come la classificazione \textit{KNN}, sia tecniche \textit{eager}, come \textit{Naive Bayes} e \textit{Decision Trees}. L’analisi si è concentrata principalmente sulla classificazione della colonna \textit{Rating} utilizzando come \textit{feature} le coppie \textit{AgeRec}-\textit{Weight} e \textit{NumDesires}-\textit{YearPublished}.

Per tutti gli algoritmi di classificazione, il \textit{dataset} è stato suddiviso in due parti: il $70\%$ dei dati è stato utilizzato per il \textit{training} dei modelli, mentre il restante $30\%$ è stato riservato come \textit{dataset} di test. La suddivisione è stata effettuata in modo randomico, al fine di ridurre possibili effetti di \textit{bias} e garantire che entrambe le parti rappresentassero adeguatamente l’interezza dei dati.

\subsection{Classificazione KNN}
\label{sec:class_knn}

Abbiamo iniziato utilizzando il metodo di classificazione basato sui primi \textit{k} vicini, ovvero la classificazione \textit{KNN}, per stimare il \textit{Rating} utilizzando \textit{NumDesires} e \textit{YearPublished} come \textit{feature}.

Prima di applicare l’algoritmo, abbiamo rimosso tutte le righe contenenti valori \textit{NaN} ed effettuato una standardizzazione basata sullo \textit{Z-score}, che porta le \textit{feature} ad avere media nulla e deviazione standard unitaria. Questa operazione è necessaria in quanto l’algoritmo si basa sulla distanza euclidea, e quindi è necessario che le variabili siano confrontabili sulla stessa scala. In questo modo, colonne come \textit{YearPublished} e \textit{NumDesires} contribuiscono in maniera bilanciata alla metrica Euclidea, evitando che una \textit{feature} domini rispetto alle altre.

\subsubsection{Selezione del parametro \textit{k}}

Per individuare il valore ottimale di \textit{k}, abbiamo calcolato l’accuratezza del modello al variare di questo parametro utilizzando una \textit{10-fold cross validation} e mediando i risultati ottenuti. L’accuratezza è stata calcolata come il rapporto tra il numero di predizioni corrette (veri positivi e veri negativi per ciascuna classe) e il numero totale di osservazioni.

Questa procedura consente di ottenere una stima più robusta delle prestazioni del modello, riducendo la dipendenza dalla particolare suddivisione tra \textit{training} e \textit{test set}.

\begin{figure}[ht!]
	\includegraphics[width=0.9\linewidth]{../figures/classification/KNN/NumDesires_YearPublished/KNN_K_Search_Accuracy_Rating.png}
	\centering
	\caption{Accuratezza in funzione di \textit{k}, calcolata tramite \textit{10-fold cross-validation}, con \textit{k} variabile tra $1$ e $96$ in passi di $5$. Si osserva che $k=26$ massimizza l’accuratezza del modello.}
	\label{fig:k_sel_class_ND_YP}
\end{figure}

Come mostrato in figura \ref{fig:k_sel_class_ND_YP}, il valore $k=26$ corrisponde alla massima accuratezza media. Di conseguenza, questo valore è stato utilizzato nelle analisi successive.

\subsubsection{Analisi del modello}

Dopo aver preparato i dati e selezionato il valore ottimale del parametro, abbiamo eseguito l’algoritmo di classificazione \textit{KNN} con $k=26$. Come prima analisi delle prestazioni, abbiamo esaminato la matrice di confusione ottenuta applicando il modello ai dati di \textit{test}, riportata in figura \ref{fig:confusion_matrix_ND_YP}.

\begin{figure}[ht!]
	\includegraphics[width=0.9\linewidth]{../figures/classification/KNN/NumDesires_YearPublished/KNN_Confusion_Matrix_Rating.png}
	\centering
	\caption{Matrice di confusione per il target \textit{Rating}, utilizzando \textit{NumDesires} e \textit{YearPublished} come \textit{feature}.}
	\label{fig:confusion_matrix_ND_YP}
\end{figure}

Dalla matrice di confusione si osserva che accuratezza, precisione e richiamo si trovano intorno al $59\%$. 

Per determinare se questo valore di accuracy è statisticamente significativo, è stata effettuata un'analisi su una 10-fold-Cross-Validation. Il modello proposto è stato confrontato con altri due di riferimento: un \textit{Dummy classifier} che risponde sempre con la classe più frequente (per verificare le capacità del modello di superare gli sbilanciamenti nella classe \textit{target}) e un modello addestrato su \textit{target} permutati casualmente, per comprendere se effettivamente il modello supera la semplice selezione casuale. Assumendo che le stime delle accuratezze seguano una distribuzione Normale (approssimazione valida per grandi campioni) con media pari all'accuratezza osservata $p$ e varianza derivata dalla distribuzione binomiale $\sigma_{p}^{2} = \frac{p (1-p)}{n}$, è possibile definire l'intervallo di confidenza al 95\% per la differenza $d$ tra le performance dei due modelli come segue:

\[
d \in \left[ \hat{d} - Z_{\alpha/2}\sigma_{d} \,;\, \hat{d} + Z_{\alpha/2}\sigma_{d} \right]
\]

dove $\hat{d}$ rappresenta la differenza osservata tra le medie e $\sigma_d$ l'errore standard combinato.

Nel KNN proposto sulle feature si osservano i seguenti risultati:


\begin{table}[ht]
\centering
\begin{tabular}{|l|c|}
	\hline
	\textbf{Modelli} & $d$ \textbf{ @ 95\% CL} \\
	\hline
	Reale vs Dummy & $0.141 \pm 0.012$ \\
	Reale vs Random & $0.185 \pm 0.015$ \\
	\hline
\end{tabular}
\caption{Risultati del test statistico di confronto tra l'accuratezza del modello reale e i baseline \textit{dummy} e \textit{random} per la classificazione del \textit{target} \textit{results} con algoritmo basato sul \textit{KNN}.}
\label{tab:real_dummy_random_table_KNN}
\end{table}


Siccome entrambi gli intervalli sono sempre positivi possiamo dire che il nostro modello è più accurato con un livello di confidenza al 95\% rispetto agli altri due.

Si nota inoltre che la classe $-1$ viene confusa meno frequentemente con la classe $1$ rispetto alla classe $0$, indicando che giochi con valutazioni estremamente positive o negative risultano più facilmente distinguibili rispetto a quelli con valutazione intermedia, che non ci sorprende come risultato.

Per valutare la separabilità delle classi, abbiamo costruito le \textit{ROC curve} per ciascuna classe del target, considerando le altre due come classe negativa. A partire da queste curve abbiamo calcolato l’\textit{AUC (Area Under Curve)} come metrica di valutazione. La \textit{ROC curve} rappresenta il compromesso tra il tasso di veri positivi e quello di falsi positivi al variare della soglia di classificazione.

\begin{figure}[ht!]
	\includegraphics[width=0.9\linewidth]{../figures/classification/KNN/NumDesires_YearPublished/KNN_Combined_ROC_Rating.png}
	\centering
	\caption{\textit{ROC curve} per il target \textit{Rating} utilizzando \textit{NumDesires} e \textit{YearPublished}. La linea tratteggiata rappresenta un classificatore casuale privo di potere discriminante.}
	\label{fig:ROC_ND_YP}
\end{figure}

Come mostrato in figura \ref{fig:ROC_ND_YP}, la classe $-1$ risulta la più facilmente distinguibile ($AUC = 0.82$), mentre la classe $0$ è la più difficile da separare ($AUC = 0.65$). Questo è coerente con l’interpretazione del \textit{Rating} medio come classe di transizione tra valutazioni positive e negative.

Tuttavia, la \textit{ROC curve} non fornisce informazioni sulla distribuzione delle classi. Per completare l’analisi del modello abbiamo quindi considerato anche le \textit{precision-recall curves}, costruite ordinando le predizioni sul \textit{dataset} di test e valutando precisione e richiamo al variare della soglia di classificazione. 

\begin{figure}[ht!]
	\includegraphics[width=0.9\linewidth]{../figures/classification/KNN/NumDesires_YearPublished/KNN_Combined_Precision_Recall_Rating.png}
	\centering
	\caption{\textit{Precision-recall curve} per il target \textit{Rating} utilizzando \textit{NumDesires} e \textit{YearPublished}.}
	\label{fig:P_R_ND_YP}
\end{figure}

I risultati, riportati in figura \ref{fig:P_R_ND_YP}, mostrano che la classe $1$, pur presentando una buona \textit{AUC} nella \textit{ROC curve}, perde rapidamente precisione all’aumentare del richiamo. Questo comportamento è dovuto al fatto che si tratta della classe meno popolata: per individuare un numero maggiore di giochi con \textit{Rating} alto è necessario accettare una precisione inferiore rispetto alle altre classi.

È stato fatto anche un tentativo utilizzando il modello KNN invece che sulla colonna \textit{Rating} su due elementi della colonna \textit{Description}, ovvero "Action" e "Roll"; per vedere se il modello fosse capace di classificare il genere di un gioco. Per applicare il KNN sono state selezionate le colonne numeriche \textit{Weight} e \textit{AgeRec}.

Per prima cosa è stato filtrato il dataset per mantenere solo quelle \textit{entries} che contengono almeno uno tra "Action" e "Roll" nella loro colonna \textit{Description}. Sono stati selezionati questi due descrittori perchè sono sufficientemente popolati (5000 elementi nel \textit{training dataset} e 2000 nel \textit{test dataset}) e coprono principalmente due aree del piano distinte. 

\begin{figure}[ht!]
	\includegraphics[width=0.9\linewidth]{../figures/classification/KNN/AgeRec_Weight/KNN_K_Search_Accuracy_roll_action.png}
	\centering
	\caption{Accuratezza in funzione di \textit{k}, calcolata tramite \textit{10-fold cross-validation}, con \textit{k} variabile tra $1$ e $96$ in passi di $5$}
	\label{fig:k_sel_class_W_AR_roll_action}
\end{figure}

Per il valore di \textit{k} è stata seguita la stessa procedura di prima, arrivando ad utilizzare un valore di \textit{k} pari a $30$.

\begin{figure}[ht!]
	\includegraphics[width=0.9\linewidth]{../figures/classification/KNN/AgeRec_Weight/KNN_Confusion_Matrix_roll_action.png}
	\centering
	\caption{Matrice di confusione per il target \textit{roll-action}, utilizzando \textit{Weight} e \textit{AgeRec} come \textit{features}.}
	\label{fig:confusion_matrix_W_AR_roll_action}
\end{figure}

\begin{figure}[ht!]
	\includegraphics[width=0.9\linewidth]{../figures/classification/KNN/AgeRec_Weight/KNN_Combined_ROC_roll_action.png}
	\centering
	\caption{\textit{ROC curve} per il target \textit{roll-action} utilizzando \textit{Weight} e \textit{AgeRec}. La linea tratteggiata rappresenta un classificatore casuale privo di potere discriminante.}
	\label{fig:ROC_W_AR_roll_action}
\end{figure}

\begin{figure}[ht!]
	\includegraphics[width=0.9\linewidth]{../figures/classification/KNN/AgeRec_Weight/KNN_Combined_Precision_Recall_roll_action.png}
	\centering
	\caption{\textit{Precision-recall curve} per il target \textit{roll-action} utilizzando \textit{Weight} e \textit{AgeRec} come \textit{features}.}
	\label{fig:P_R_W_AR_roll_action}
\end{figure}

Dalle figure \ref{fig:confusion_matrix_W_AR_roll_action}, \ref{fig:ROC_W_AR_roll_action} e \ref{fig:P_R_W_AR_roll_action} è evidente come il modello non riesca a classificare i giochi che sono sia "roll" che "action", probabilmente perchè esistono pochi punti con questa doppia caratteristica. Il modello comunque mostra dei risultati soddisfacenti nel differenziare le due classi, soprattutto se lo confrontiamo con i due modelli \textit{random} e \textit{dummy}:

\begin{table}[ht]
\centering
\begin{tabular}{|l|c|}
	\hline
	\textbf{Modelli} & $d$ \textbf{ @ 95\% CL} \\
	\hline
	Reale vs Dummy & $0.059  \pm 0.020$ \\
	Reale vs Random & $0.074  \pm 0.019$ \\
	\hline
\end{tabular}
\caption{Risultati del test statistico di confronto tra l'accuratezza del modello reale e i baseline \textit{dummy} e \textit{random} per la classificazione del \textit{target} "action-roll" con algoritmo basato sul \textit{KNN}.}
\label{tab:real_dummy_random_table_KNN_RA}
\end{table}

\subsection{Naive Bayes}

Come algoritmo successivo abbiamo utilizzato il \textit{Naive Bayes}, con l’obiettivo di classificare il \textit{Rating} di un gioco a partire da un insieme di \textit{feature}. Poiché il \textit{Naive Bayes} è particolarmente adatto alla gestione di \textit{feature} categoriche, abbiamo incluso la variabile \textit{Family} come attributo aggiuntivo, insieme a \textit{NumDesires} e \textit{YearPublished}. 

Come nel caso precedente, abbiamo iniziato rimuovendo dal \textit{dataset} tutte le righe contenenti valori \textit{NaN} e standardizzando le variabili numeriche per portarle ad avere media nulla e deviazione standard unitaria. Questo implica che l’analisi è stata condotta esclusivamente sui giochi appartenenti ad almeno una famiglia: i giochi non associati ad alcuna famiglia sono stati trattati come \textit{NaN} e quindi rimossi. Di conseguenza, l’analisi è stata effettuata su circa il $30\%$ del \textit{dataset} iniziale, limitandosi ai soli giochi associati ad una famiglia.

Abbiamo utilizzato il modello \textit{MixedNB} del pacchetto \textit{mixed-naive-bayes}, estensione di \textit{scikit-learn}, che tratta le \textit{feature} numeriche come variabili gaussiane e utilizza una \textit{likelihood} multibernoulliana per le \textit{feature} categoriche. A ciascuna categoria è stata assegnata una chiave numerica tramite \textit{ordinal encoding}. Come per la classificazione \textit{KNN}, abbiamo analizzato le prestazioni del modello tramite matrice di confusione, \textit{ROC curves} e curve di precisione--richiamo. Tutti i risultati sono riportati in figura \ref{fig:dashboard_NB}.

\begin{figure}[ht!]
	\includegraphics[width=0.9\linewidth]{../figures/classification/NB/NB_Full_Summary_Report_Rating.png}
	\centering
	\caption{Matrice di confusione, \textit{ROC curves} e curve di precisione--richiamo per il target \textit{Rating}, utilizzando \textit{NumDesires} e \textit{YearPublished} come \textit{feature} numeriche e \textit{Family} come \textit{feature} categorica.}
	\label{fig:dashboard_NB}
\end{figure}

Analogamente al caso del \textit{KNN}, accuratezza, precisione e richiamo indicano che il modello classifica correttamente i dati con una frequenza significativamente maggiore rispetto a un classificatore casuale. Paragonando, come nella sezione precedente, l'accuratezza con un modello \textit{dummy} e randomico, si ottengono i seguenti valori:

\begin{table}[ht]
\centering
\begin{tabular}{|l|c|}
    \hline
    \textbf{Modelli} & $d$ \textbf{ @ 95\% CL} \\
    \hline
    Reale vs Dummy & $0.229 \pm 0.020$ \\
    Reale vs Random & $0.274 \pm 0.020$ \\
    \hline
\end{tabular}
\caption{Risultati del test statistico di confronto tra l’accuratezza del modello reale e i baseline \textit{dummy} e \textit{random} per la classificazione tramite un modello \textit{naive Bayes}.}
\label{tab:real_dummy_random_table_NB}
\end{table}

Anche in questo caso, il classificatore risulta significativo e la classe più difficile da classificare risulta essere la classe $0$, in quanto intermedia tra le altre due. Tutte le metriche risultano complessivamente migliori rispetto a quelle ottenute con il \textit{KNN}, suggerendo che l’inclusione della variabile \textit{Family} abbia fornito informazione aggiuntiva utile alla classificazione.

Tuttavia, l’introduzione di questa \textit{feature} comporta una restrizione del \textit{dataset} analizzato, introducendo un \textit{bias} a priori: il modello viene infatti addestrato e valutato esclusivamente sui giochi appartenenti a una famiglia, e non sull’interezza del \textit{dataset} originale.

Infine, è importante ricordare che il \textit{Naive Bayes} assume l’indipendenza condizionata tra le \textit{feature}. Sebbene le variabili considerate non presentino forti correlazioni, non possono essere considerate completamente indipendenti. Nonostante questa limitazione, la tecnica del \textit{Naive Bayes} si è dimostrata robusta e particolarmente utile, permettendo di integrare efficacemente \textit{feature} numeriche e categoriche all’interno del processo di classificazione.


\subsection{Decision Trees}

Come ultima tecnica di classificazione abbiamo utilizzato i \textit{decision trees} per determinare il \textit{Rating} dei giochi. Come nelle sezioni precedenti, abbiamo suddiviso il \textit{dataset} in \textit{training set} e \textit{test set}, rimosso i \textit{NaN} e standardizzato le variabili numeriche. Anche in questo caso, sono state utilizzate le colonne \textit{NumDesires} e \textit{YearPublished} come \textit{feature} per la classificazione del \textit{rating}.

\subsubsection{Selezione dei parametri}

Per ottimizzare le prestazioni del modello e individuare i valori migliori per \textit{max depth}, \textit{min samples per leaf}, \textit{min samples per split} e \textit{criterion} (tra \textit{gini} ed \textit{entropy}), è stata effettuata una ricerca degli iperparametri tramite \textit{RandomizedSearchCV} di \textit{scikit-learn}. Sono state analizzate 500 combinazioni casuali attraverso una \textit{cross-validation} a 5 fold. Il processo ha permesso di individuare la configurazione ottimale (\textit{max depth}$=7$, \textit{min samples per leaf}$=100$, \textit{min samples per split}$=80$, \textit{criterion}=\textit{gini}), stabilizzando l’accuratezza sul \textit{test set} al $60.6\%$. I risultati sono riportati in figura \ref{fig:dt_hyperP_tuning}.

\begin{figure}[ht!]
	\includegraphics[width=0.9\linewidth]{../figures/classification/decision_tree/NumDesires_YearPublished/dt_hyperparameter_tuning_Rating.png}
	\centering
	\caption{Risultati dell’ottimizzazione degli iperparametri tramite \textit{RandomizedSearchCV}. I grafici mostrano come la variazione dei parametri influenzi l’accuratezza media in \textit{cross-validation}.}
	\label{fig:dt_hyperP_tuning}
\end{figure}

Si osserva inoltre che la scelta del \textit{criterion} tra \textit{entropy} e \textit{gini} risulta poco influente sulla bontà complessiva del modello.

In aggiunta, abbiamo studiato la complessità del modello al variare di alcuni parametri, analizzando l’effetto della profondità massima e di \textit{min samples per leaf} sull’accuratezza e sul numero di nodi dell’albero, con l’obiettivo di evitare fenomeni di \textit{overfitting} e controllare la complessità del modello.

\begin{figure}[ht!]
	\includegraphics[width=0.9\linewidth]{../figures/classification/decision_tree/NumDesires_YearPublished/dt_complexity_analysis_Rating.png}
	\centering
	\caption{Analisi della complessità del modello di \textit{decision trees} per la classificazione del \textit{Rating}.}
	\label{fig:dt_complexity_analysis}
\end{figure}

Dalla figura \ref{fig:dt_complexity_analysis} si osserva chiaramente che la scelta di \textit{max depth}$=7$ e \textit{min samples per leaf}$=100$ consente di ottenere la massima accuratezza senza introdurre problemi di \textit{overfitting} sul \textit{test set}. Questa configurazione permette di mantenere il modello sufficientemente semplice e generalizzabile a dati non visti.

\subsubsection{Analisi del modello}

Fissati i migliori valori degli iperparametri, abbiamo analizzato la qualità del modello in maniera analoga ai casi precedenti. La figura \ref{fig:dt_dashboard} mostra la matrice di confusione, le \textit{ROC curves} e le curve di \textit{precision--recall}, fornendo una visione sintetica delle prestazioni del classificatore.

\begin{figure}[ht!]
	\includegraphics[width=0.9\linewidth]{../figures/classification/decision_tree/NumDesires_YearPublished/decision_tree_Full_Summary_Report_Rating.png}
	\centering
	\caption{Matrice di confusione, \textit{ROC curves} e curve di precisione--richiamo per il target \textit{Rating}, utilizzando \textit{NumDesires} e \textit{YearPublished} come \textit{feature}, tramite un modello di \textit{decision trees}.}
	\label{fig:dt_dashboard}
\end{figure}

Il modello raggiunge un’accuratezza del $60.6\%$, che viene confrontata con un modello casuale e un modello \textit{dummy}, come già discusso nella sezione \ref{sec:class_knn}.

\begin{table}[ht]
\centering
\begin{tabular}{|l|c|}
    \hline
    \textbf{Modelli} & $d$ \textbf{ @ 95\% CL} \\
    \hline
    Reale vs Dummy & $0.161 \pm 0.012$ \\
    Reale vs Random & $0.171 \pm 0.015$ \\
    \hline
\end{tabular}
\caption{Risultati del test statistico di confronto tra l’accuratezza del modello reale e i baseline \textit{dummy} e \textit{random} per la classificazione tramite \textit{decision trees}.}
\label{tab:real_dummy_random_table_DT}
\end{table}

Poiché entrambi gli intervalli riportati in \ref{tab:real_dummy_random_table_DT} risultano positivi, possiamo concludere che il modello è significativamente più accurato rispetto ai due baseline con un livello di confidenza del $95\%$, rendendolo accettabile come algoritmo di classificazione.

Come negli altri casi, la classe $0$ risulta la meno separabile, in quanto intermedia tra le classi $-1$ e $1$, mentre la classe $1$ è maggiormente influenzata dal \textit{trade-off} tra precisione e richiamo, essendo la meno popolata. Inoltre, il modello consente di estrarre l’importanza relativa delle \textit{feature} in base al loro potere discriminatorio. La figura \ref{fig:dt_feature_importance} mostra che \textit{NumDesires} influisce in maniera significativamente maggiore sul \textit{Rating} rispetto all’anno di pubblicazione.

\begin{figure}[ht!]
	\includegraphics[width=0.9\linewidth]{../figures/classification/decision_tree/NumDesires_YearPublished/dt_feature_importance_Rating.png}
	\centering
	\caption{Importanza delle \textit{feature} \textit{NumDesires} e \textit{YearPublished} nel modello di classificazione basato sui \textit{decision trees}.}
	\label{fig:dt_feature_importance}
\end{figure}


\section{Regressione}
\label{sec:regressione}

Come ulteriore strumento di predizione abbiamo studiato la dipendenza tra le colonne del \textit{dataset} utilizzando tecniche di regressione. Non ci siamo limitati alla regressione lineare, ma abbiamo esplorato anche tecniche non lineari che includono termini di regolarizzazione, algoritmi \textit{lazy} come il \textit{KNN} e \textit{eager learners} come i \textit{decision trees}. Inoltre, abbiamo analizzato la dipendenza di una variabile rispetto a due variabili indipendenti, applicando le stesse tecniche descritte in precedenza.

Come nella sezione precedente, il \textit{dataset} è stato suddiviso in due parti: il $70\%$ delle righe, selezionate randomicamente, è stato utilizzato come \textit{training set}, mentre il restante $30\%$ è stato riservato al \textit{test set}.

\subsection{Una variabile indipendente}

Come prima analisi abbiamo voluto confermare la dipendenza tra due \textit{feature} fortemente correlate, scegliendo \textit{NumWant} e \textit{NumWish}, che risultano correlate ma non perfettamente dipendenti in modo lineare.

Abbiamo utilizzato cinque tecniche di regressione: regressione lineare, regressione lineare con regolarizzazione (\textit{ridge} e \textit{lasso}), \textit{KNN} e \textit{decision trees}. Per ciascun algoritmo, i parametri sono stati fissati eseguendo il fit sul \textit{training set} e calcolando il coefficiente di determinazione $R^2$ sul \textit{test set}. Successivamente, i parametri sono stati fatti variare tramite uno \textit{sweep}, selezionando per ciascun modello il valore ottimale in corrispondenza del punto di ``gomito'' della curva. I risultati sono mostrati in figura \ref{fig:single_NumWNumW_parameter_sweep}.

\begin{figure}[ht!]
\includegraphics[width=0.9\linewidth]{../figures/classification/regression/single/hyperparameter_tuning_NumWant_vs_NumWish.png}
\centering
\caption{$R^2$ al variare dei parametri dei diversi modelli di regressione per \textit{NumWant} vs \textit{NumWish}.}
\label{fig:single_NumWNumW_parameter_sweep}
\end{figure}

I valori ottimali individuati sono $\alpha_r = 1500$ per il \textit{ridge}, $\alpha_l = 0.5$ per il \textit{lasso}, $n = 12$ per il \textit{KNN} e \textit{max\_depth}$=4$ per il \textit{decision tree}. Fissati questi iperparametri, abbiamo eseguito le regressioni per tutti i modelli, ottenendo i risultati riportati in figura \ref{fig:single_NumWNumW}.

\begin{figure}[ht!]
\includegraphics[width=0.9\linewidth]{../figures/classification/regression/single/NumWant_vs_NumWish.png}
\centering
\caption{Regressione di \textit{NumWant} vs \textit{NumWish}. I punti rossi rappresentano i valori predetti sul \textit{test set}, mentre i punti blu rappresentano i valori reali del \textit{dataset}.}
\label{fig:single_NumWNumW}
\end{figure}

Come atteso, tutte e cinque le regressioni forniscono ottimi risultati, riuscendo a spiegare oltre l’$80\%$ della varianza osservata nei dati.

Successivamente, ci siamo concentrati sulla relazione tra \textit{WeightedRating} e \textit{NumDesires}, con l’obiettivo di predire il punteggio di un gioco in funzione dell’interesse mostrato dagli utenti. Utilizzando gli stessi cinque modelli e la medesima procedura di selezione degli iperparametri, abbiamo ottenuto i risultati riportati in figure \ref{fig:single_WRND_parameter_sweep} e \ref{fig:single_WRND}.

\begin{figure}[ht!]
\includegraphics[width=0.9\linewidth]{../figures/classification/regression/single/hyperparameter_tuning_WeightedRating_vs_NumDesires.png}
\centering
\caption{$R^2$ al variare dei parametri dei diversi modelli di regressione per \textit{WeightedRating} vs \textit{NumDesires}.}
\label{fig:single_WRND_parameter_sweep}
\end{figure}

\begin{figure}[ht!]
\includegraphics[width=0.9\linewidth]{../figures/classification/regression/single/WeightedRating_vs_NumDesires.png}
\centering
\caption{Regressione di \textit{WeightedRating} vs \textit{NumDesires}. I punti rossi rappresentano i valori predetti sul \textit{test set}, mentre i punti blu rappresentano i valori reali del \textit{dataset}.}
\label{fig:single_WRND}
\end{figure}

In questo caso, le due \textit{feature} risultano meno correlate rispetto a \textit{NumWant} e \textit{NumWish}, e la loro relazione non è facilmente descrivibile tramite un modello lineare. Tra i cinque modelli considerati, il \textit{decision tree} risulta quello in grado di spiegare la maggiore frazione di varianza, seguito dal \textit{KNN}. Questi risultati suggeriscono che modelli più complessi, eventualmente includendo ulteriori \textit{feature} indipendenti, potrebbero fornire una descrizione più accurata della variabilità di \textit{WeightedRating}.

\subsection{Due variabili indipendenti}

Nel caso di due variabili indipendenti abbiamo considerato come variabile dipendente la colonna \textit{WeightedRating}, con l’obiettivo di predire il successo di un gioco in funzione delle sue caratteristiche. Sono state testate tutte le coppie tra le colonne \textit{Weight}, \textit{Playtime}, \textit{AgeRec}, \textit{NumDesires} e \textit{LanguageEase}, trovando che i risultati migliori si ottengono utilizzando la coppia \textit{NumDesires} e \textit{Weight}.

Abbiamo utilizzato gli stessi cinque algoritmi della sezione precedente e selezionato i migliori iperparametri tramite uno \textit{sweep}, valutando il coefficiente $R^2$ sul \textit{test set}. I risultati sono mostrati in figura \ref{fig:regression_parameter_sweep}.

\begin{figure}[ht!]
\includegraphics[width=0.9\linewidth]{../figures/classification/regression/multiple/hyperparameter_tuning_WeightedRating_vs_Weight_NumDesires.png}
\centering
\caption{$R^2$ al variare dei parametri dei diversi modelli di regressione per \textit{WeightedRating} in funzione di \textit{NumDesires} e \textit{Weight}.}
\label{fig:regression_parameter_sweep}
\end{figure}

Fissati i parametri ottimali, abbiamo eseguito le regressioni ottenendo i risultati riportati in figura \ref{fig:regression_WR_R_NumD}.

\begin{figure}[ht!]
\includegraphics[width=0.9\linewidth]{../figures/classification/regression/multiple/comparison_5x2_WeightedRating_vs_Weight_NumDesires.png}
\centering
\caption{Regressione di \textit{WeightedRating} vs \textit{NumDesires} e \textit{Weight}. I punti rossi rappresentano i valori predetti sul \textit{test set}, mentre i punti blu rappresentano i valori reali del \textit{dataset}.}
\label{fig:regression_WR_R_NumD}
\end{figure}

Considerando il coefficiente $R^2$ come metrica di valutazione, il miglior risultato è ottenuto tramite il modello basato sui \textit{decision trees}, che riesce a spiegare circa il $44\%$ della varianza. Rispetto al caso con una sola variabile indipendente, anche gli altri modelli mostrano un miglioramento, spiegando almeno il $30\%$ della varianza. Questo suggerisce che, sebbene la coppia di variabili considerate non sia sufficiente a spiegare completamente la variabilità di \textit{WeightedRating}, essa fornisce comunque un indicatore significativo della valutazione di un gioco, migliorando sensibilmente rispetto alla regressione basata esclusivamente su \textit{NumDesires}.

\section{Pattern Mining}

Come ultima analisi abbiamo applicato due algoritmi di \textit{pattern mining} al dataset per trovare correlazioni e identificare strutture ricorrenti. Per fare questo abbiamo scelto delle colonne sia numeriche che categoriche e abbiamo cercato delle "regole" che potessero essere interessanti sfruttando gli algoritmi "Apriori" e "FPGrowth". Come colonne categoriche sono state scelte: \textit{'YearPublished'}, \textit{'AgeRec'}, \textit{'Playtime'} e \textit{LanguageEase}; mentre tra quelle categoriche ci sono: \textit{'MinPlayers'}, \textit{'MaxPlayers'} \textit{'IsReimplementation'}, \textit{'Kickstarted'} e \textit{'Rating'}. Per le classi numeriche è stato deciso di fare un binning a 5 classi per ridurre il numero di operazioni da fare e rendere l'algoritmo più veloce. Per quanto riguarda i missing values è stato deciso di usare la mediana di campione per sostituire eventuali elementi vuoti, in quanto i nostri dati spesso non sono distribuiti simmetricamente (\textit{skeweness} alta).

Successivamente abbiamo applicato gli stessi algoritmi sugli elementi della colonna "Description", al fine di osservare se alcuni giochi hanno delle regole.

Applicando entrambi gli algoritmi si osserva che i risultati sono (giustamente) identici, ma l'algoritmo "FPGrowth" è sensibilmente più rapido. Perciò mostreremo solo i risultati di quest'ultimo algoritmo.

Per ciascuno degli esempi abbiamo prima cercato degli \textit{itemset} con un supporto minimo, successivamente abbiamo applicato l'algoritmo per cercarele regole.
Quindi abbiamo applicato l'algoritmo "FPGrowth" alle colonne sopra indicate utilizzando i seguenti parametri: 

\begin{itemize}
\item $min\_support$ = 10 \%
\item $z\_min$ = 2
\item $z\_max$ = 5
\end{itemize}

Il parametro \textit{$min\_support$} si riferisce al supporto minimo che ciascun elemento (o insieme di elementi) deve avere per poter essere considerato, $z\_min$ e $z\_max$ sono i limiti nel numero di elementi che possono appartenere ad un \textit{itemset}. Alcuni itemset con il supporto molto elevato sono:

\begin{table}[ht]
\centering
\begin{tabular}{|l|l|}
	\hline
	Itemset &Supp.} \\
	\hline
	Kickst.=No, IsReimpl.=No & 74.60\\
	MinPlayers=2, IsReimpl.=No &   60.81 \\
	MinPlayers=2, Kickst.=No    & 59.79 \\
        MinPlayers=2, Kickst.=No, IsReimpl.=No &   52.83 \\
        LanguageEase=41-138, IsReimpl.=No &    41.92 \\
	\hline
\end{tabular}
\caption{Itemset con valore più alto di supporto, applicando l'algoritmo FPGrowth}
\end{table}

Si osserva come la maggioranza dei giochi non sia avviata con un \textit{Kickstarted} e non è una reimplementazione di qualche altro gioco, in più sono molto comuni anche i giochi con 2 giocatori e con una difficoltà nel linguaggio piuttosto bassa (Si ricorda che LanguageEase va da 0 a oltre i 600; 41-138 è il secondo di 5 bin).

Successivamente è stato applicato l'algoritmo per trovare delle regole. Per verificare se una regola è effettivamente valida si è calcolato per ciascuna regola il \textit{lift} e si sono prese quelle col lift più alto. Inoltre sono state considerate solo le regole con confidence maggiore del 50 \%. L'algoritmo ha restituito queste regole:

\begin{table}[ht!]
    \centering
    % Imposta il font piccolo per tutta la tabella
    \footnotesize 
    % (Opzionale) Riduci leggermente lo spazio verticale tra le righe per compattare
    \renewcommand{\arraystretch}{1.2} 
    \caption{Regole di associazione estratte}
    \label{tab:rules_agerec}

    \begin{tabular}{@{} p{0.05\linewidth} p{0.9\linewidth} @{}} 
        \hline
        
        \textbf{1.} & \{Playt.=90-240, Kick.=No, IsReimpl.=No\} $\to$ Age=10-12 \\
         & \textit{Supp: 6.45\% \quad Conf: 56.62\% \quad Lift: 2.46} \\ 
        \hline
        
        \textbf{2.} & \{Playt.=90-240, MinPlay.=2\} $\to$ Age=10-12 \\
         & \textit{Supp: 5.80\% \quad Conf: 56.16\% \quad Lift: 2.44} \\ 
        \hline
        
        \textbf{3.} & \{Playt.=90-240, Kick.=No\} $\to$ Age=10-12 \\
         & \textit{Supp: 7.28\% \quad Conf: 55.88\% \quad Lift: 2.43} \\ 
        \hline
        
        \textbf{4.} & \{Playt.=90-240, IsReimpl=No\} $\to$ Age=10-12 \\
         & \textit{Supp: 7.08\% \quad Conf: 51.73\% \quad Lift: 2.25} \\ 
        \hline
        
        \textbf{5.} & \{Playt.=90-240\} $\to$ Age=10-12 \\
         & \textit{Supp: 8.00\% \quad Conf: 51.09\% \quad Lift: 2.22} \\ 
        \hline  
    \end{tabular}
\end{table}

Il \textit{Lift} rappresenta la metrica più significativa per valutare l'effettiva utilità di una regola di associazione, poiché depura il risultato dalla semplice popolarità del conseguente. Definito come il rapporto tra la confidenza della regola e il supporto atteso del conseguente ($Lift(A \to B) = \frac{P(B|A)}{P(B)}$), il Lift misura quanto l'antecedente aumenti la probabilità che si verifichi l'evento target rispetto al caso puramente casuale. 

Mentre un valore pari a 1 indicherebbe indipendenza statistica tra le variabili, i valori ottenuti nella nostra analisi (Tabella \ref{tab:rules_agerec}), attestandosi intorno a $2.46$, evidenziano una forte correlazione positiva. Ciò implica che la presenza delle caratteristiche nell'antecedente (es. un \textit{Playtime} di 90--240 minuti) incrementa di quasi 2.5 volte la probabilità che il gioco sia destinato alla fascia d'età 10--12 anni rispetto alla media del dataset, confermando che la regola descrive un legame strutturale e non una mera coincidenza distributiva.

Andando avanti a lift più bassi si trovano regole tipo:
\[
\hline
\{Age=6-8, Rating=0\} \to Playtime=15-30 

\textit{Supp: 8.05\% \quad Conf: 64.1\% \quad Lift: 1.86}
\hline
\{Rating=-1, Playtime=15-30\} \to Age=6-8


\textit{Supp: 7.63\% \quad Conf: 51.88\% \quad Lift: 1.81}
\hline
\]

Quindi si osserva una correlazione tra i giochi che durano poco e i ragazzi tra i 6 e gli 8 anni, soprattutto nei giochi valutati peggio. Un'altra relazione interessante è la seguente:
\[
\hline
\{Year=1978--2002\} \to Rating=-1 

\textit{Supp: 10.78\% \quad Conf: 51.32\% \quad Lift: 1.55}
\hline
\]

Dove si vede che i giochi vecchi sono più spesso valutati male.

Il passo successivo è stato quello di effettuare le stesse pratiche anche sulla colonna \textit{Description}, usando le liste di descrittori come itemset. Come prima abbiamo osservato gli itemset con il supporto più elevato, mantenendo gli iperparametri sempre gli stessi dell'analisi precedente, ottenendo i seguenti itemset più frequenti:

\begin{table}[ht]
\centering
\begin{tabular}{|l|l|}
    \hline
    Itemset & Supp. (\%) \\
    \hline
    (player, game) & 69.14 \\
    (card, game)   & 43.33 \\
    (play, game)   & 42.74 \\
    (card, player) & 41.29 \\
    (play, player) & 39.16 \\
    \hline
\end{tabular}
\caption{Itemset frequenti estratti dai descrittori testuali (FPGrowth)}
\label{tab:itemsets_descriptors}
\end{table}

Si osserva subito come gli elementi più frequenti nei descrittori (visti nella Figura \ref{fig:top_words}) sono anche quelli più presenti negli itemset col supporto più alto.

Andando avanti con l'analisi si sono cercate le regole con supporto e confidence maggiori del 10 \%, in quanto il numero di elementi singoli è molto maggiore e ciò porta ad un calo delle confidence. I risultati con il \textit{Lift} più alto sono i seguenti:

\begin{table}[ht!]
    \centering
    % Imposta il font piccolo
    \footnotesize 
    % Spazio verticale tra le righe
    \renewcommand{\arraystretch}{1.2} 
    \caption{Regole di associazione estratte dai descrittori testuali}
    \label{tab:rules_descriptors}

    \begin{tabular}{@{} p{0.05\linewidth} p{0.9\linewidth} @{}} 
        \hline
        
        \textbf{1.} & \{war, game\} $\to$ civil \\
         & \textit{Supp: 1.35\% \quad Conf: 11.80\% \quad Lift: 7.39} \\ 
        \hline
        
        \textbf{2.} & \{war\} $\to$ civil \\
         & \textit{Supp: 1.46\% \quad Conf: 11.52\% \quad Lift: 7.22} \\ 
        \hline
        
        \textbf{3.} & \{war, game\} $\to$ ii \\
         & \textit{Supp: 1.75\% \quad Conf: 15.31\% \quad Lift: 6.25} \\ 
        \hline
        
        \textbf{4.} & \{war\} $\to$ ii \\
         & \textit{Supp: 1.85\% \quad Conf: 14.58\% \quad Lift: 5.95} \\ 
        \hline
        
        \textbf{5.} & \{map, game\} $\to$ chart \\
         & \textit{Supp: 1.23\% \quad Conf: 12.26\% \quad Lift: 5.50} \\ 
        \hline  
    \end{tabular}
\end{table}

È evidente come i giochi di guerra spesso siano legati alla guerra civile e alla seconda guerra mondiale, portando ad un lift molto elevato per queste regole. Un'altro insieme di regole interessanti è il seguente:

\[
\begin{array}{l}
\hline
\{map\} \to chart \\
\textit{Supp: 1.30\% \quad Conf: 11.97\% \quad Lift: 5.37} \\
\hline
\{map, game\} \to mile \\
\textit{Supp: 1.06\% \quad Conf: 10.62\% \quad Lift: 5.35} \\
\hline
\{map\} \to division \\
\textit{Supp: 1.23\% \quad Conf: 11.38\% \quad Lift: 5.34} \\
\hline
\{map\} \to hex \\
\textit{Supp: 2.11\% \quad Conf: 19.51\% \quad Lift: 5.26} \\
\hline
\end{array}
\]

Ovvero che i giochi che hanno una mappa spesso sono anche divisi in miglia oppure in esagoni. 

Altre regole osservate sono:

\[
\begin{array}{l}
\hline
\{dice, player\} \to roll \\
\textit{Supp: 6.80\% \quad Conf: 60.64\% \quad Lift: 5.20} \\
\hline
\{deck, card, player \} \to shuffle \\
\textit{Supp: 1.47\% \quad Conf: 13.10\% \quad Lift: 5.10} \\
\hline
\end{array}
\]

Ovvero che molti giochi coi dadi prevedono dei tiri e che quelli con le carte prevedono di mescolare, regole quasi ovvie ma sinonimo del fatto che il metodo per trovare delle regole funziona bene.

In conclusione si può dire che si osservano molte regole legate alla guerra, ai giochi di carte e ai giochi coi dadi.

\section{Conclusioni}

In questo progetto abbiamo svolto un’analisi completa del \textit{dataset} proveniente da BoardGameGeek, affrontando in modo sistematico tutte le fasi del processo di preparazione ed esplorazione dei dati. A partire da una prima comprensione delle variabili, abbiamo identificato criticità strutturali e incoerenze semantiche, applicando una pulizia approfondita che ha permesso di rimuovere valori impossibili, gestire correttamente i dati mancanti e uniformare gli attributi secondo il loro dominio.

La fase di analisi univariata e bivariata ha permesso di evidenziare le principali tendenze del \textit{dataset}: una forte asimmetria nelle variabili legate alla popolarità e all’engagement degli utenti, la predominanza di giochi semplici e adatti a pochi giocatori, e pattern chiari nella distribuzione delle categorie di classificazione. L’uso di istogrammi, \textit{scatterplots} e matrici di correlazione ha inoltre confermato la presenza di gruppi di variabili sostanzialmente ridondanti, spesso riconducibili allo stesso concetto o a misure strettamente correlate.

Questi risultati hanno guidato la fase di \textit{data preparation and filtering}, durante la quale abbiamo ridotto la dimensionalità del \textit{dataset} tramite tecniche di aggregazione. In particolare, abbiamo utilizzato la \textit{PCA} per sintetizzare coppie di variabili fortemente correlate e una trasformazione basata sul \textit{Bayesian shrinkage} per costruire una misura più informativa del \textit{rating} degli utenti. Un \textit{sampling} finale ha inoltre permesso di ridurre la dimensione del \textit{dataset}, rendendolo più maneggevole senza perderne le caratteristiche statistiche principali. Il risultato è un insieme di dati più compatto, coerente e adatto ad analisi predittive.

Sul \textit{dataset} così preparato abbiamo applicato diverse tecniche di \textit{clustering}, tra cui metodi \textit{density-based}, \textit{k-means} e \textit{hierarchical}. Pur individuando strutture locali nei dati, nessuna di queste tecniche ha evidenziato \textit{clusters} ben separati o interpretabili in modo convincente. Questo risultato suggerisce che i giochi da tavolo non si organizzano in gruppi distinti, ma coprono piuttosto uno spettro continuo di caratteristiche, in cui per ogni tipologia di utente esistono molteplici giochi potenzialmente adatti.

Abbiamo poi affrontato il problema della predizione del \textit{rating} tramite tecniche di classificazione, utilizzando modelli \textit{lazy} come il \textit{KNN} e modelli \textit{eager} come \textit{Naive Bayes} e \textit{Decision Trees}. I risultati mostrano che, pur con accuratezze moderate, tutti i modelli considerati riescono a superare significativamente classificatori di riferimento casuali o \textit{dummy}, indicando che alcune caratteristiche dei giochi contengono effettivamente informazione predittiva sul \textit{rating}. L’inclusione di \textit{feature} categoriche, come la famiglia di appartenenza, ha inoltre migliorato le prestazioni, al prezzo però di una riduzione del \textit{dataset} analizzato.

In modo complementare, abbiamo studiato la dipendenza tra le variabili tramite tecniche di regressione, sia con una che con due variabili indipendenti, confrontando modelli lineari, regolarizzati e non lineari, inclusi \textit{KNN} e \textit{Decision Trees}. Le analisi hanno mostrato che relazioni fortemente correlate possono essere spiegate efficacemente anche da modelli semplici, mentre la predizione del \textit{WeightedRating} richiede modelli più flessibili e l’inclusione di più \textit{feature}, pur rimanendo una variabile solo parzialmente spiegabile.

L'analisi di \textit{Pattern Mining}, condotta tramite l'algoritmo FP-Growth, ha permesso di estrarre sia gli itemset più frequenti che regole di associazione significative. Dall'esame delle variabili strutturate sono emerse forti dipendenze tra l'età consigliata e la durata delle partite, oltre a una tendenza verso valutazioni inferiori per i titoli pubblicati prima del 2002. Parallelamente, l'applicazione dell'algoritmo ai descrittori testuali ha evidenziato legami tematici coerenti, associando ad esempio i giochi di guerra a specifici contesti storici reali. L'efficacia dell'estrazione è stata ulteriormente validata dalla corretta identificazione di pattern semantici noti, come quelli relativi alle meccaniche dei giochi di carte e di dadi.

Nel complesso, il lavoro svolto ha portato alla costruzione di un \textit{dataset} significativamente più coerente e informativo rispetto all’originale, permettendo di applicare in modo consapevole e critico diverse tecniche di \textit{data mining}. Le analisi di clustering, classificazione e regressione, insieme allo studio dei pattern frequenti, hanno fornito una visione articolata delle dinamiche interne al mondo dei giochi da tavolo, ponendo una solida base per future estensioni e analisi più approfondite.


\end{document}
